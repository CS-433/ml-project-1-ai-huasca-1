{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "\n",
    "from helpers import *\n",
    "from helpers_perso import *\n",
    "from nan_imputation import *\n",
    "from one_hot_encoding import *\n",
    "from implementations import *\n",
    "from standardization import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(), \"data\", \"dataset\")\n",
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(data_path)\n",
    "print(\"Data loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance across columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "column_variances = np.nanvar(x_train, axis=0)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# First subplot: Full range of variances with more bins\n",
    "axes[0].hist(column_variances, bins=100, edgecolor='black')\n",
    "axes[0].set_title(\"Distribution of Variance Across Columns (Full Range)\")\n",
    "axes[0].set_xlabel(\"Variance\")\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "\n",
    "# Second subplot: Focus on variance between 0 and 0.5\n",
    "axes[1].hist(column_variances, bins=20, range=(0, 1000), edgecolor='black')\n",
    "axes[1].set_title(\"Distribution of Variance Across Columns (0 to 1000)\")\n",
    "axes[1].set_xlabel(\"Variance\")\n",
    "axes[1].set_ylabel(\"Frequency\")\n",
    "\n",
    "# Third subplot: Focus on variance between 1 and 200\n",
    "axes[2].hist(column_variances, bins=100, range=(1, 200), edgecolor='black')\n",
    "axes[2].set_title(\"Distribution of Variance Across Columns (1 to 200)\")\n",
    "axes[2].set_xlabel(\"Variance\")\n",
    "axes[2].set_ylabel(\"Frequency\")\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling columns containing Nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proportion of Nan values in Nan-containing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the proportion of NaN values in each column\n",
    "nan_proportions = np.isnan(x_train).mean(axis=0)\n",
    "\n",
    "# Print the total number of columns plotted\n",
    "total_columns = nan_proportions.size\n",
    "print(f\"Total number of columns plotted: {total_columns}\")\n",
    "\n",
    "# Print the number of columns containing NaN values\n",
    "num_columns_with_nans = np.sum(nan_proportions > 0)\n",
    "print(f\"Number of columns containing NaN values: {num_columns_with_nans}\")\n",
    "\n",
    "# Define the bins for the histogram\n",
    "bins = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "\n",
    "# Calculate the histogram\n",
    "hist, bin_edges = np.histogram(nan_proportions, bins=bins)\n",
    "\n",
    "# Create the bar plot\n",
    "plt.bar(range(len(hist)), hist, tick_label=[f'{int(b*100)}-{int(bins[i+1]*100)}%' for i, b in enumerate(bins[:-1])])\n",
    "plt.xlabel('Proportion of NaN values')\n",
    "plt.ylabel('Number of columns')\n",
    "plt.title('Number of columns containing a proportion of NaN values')\n",
    "\n",
    "# Rotate the x-axis tick labels to vertical\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus not reasonnable to exclude columns containing Nan values\n",
    "Choice : remove columns with Nan proportion superior to 80 % ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of columns to delete (NaN proportion superior to 80.0 %): 36.14%\n",
      "Data cleaned successfully!\n",
      "Original shape of x_train: (328135, 321)\n",
      "Cleaned shape of x_train: (328135, 205)\n"
     ]
    }
   ],
   "source": [
    "# Clean all arrays by removing columns containing NaN values\n",
    "x_train_cleaned, deleted_indices = remove_nan_features(x_train, 0.8)\n",
    "\n",
    "adapted_x_test = np.delete(x_test, deleted_indices, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns containing only integer values: 182\n",
      "Percentage of integer columns that contain at least one zero: 13.19%\n"
     ]
    }
   ],
   "source": [
    "integer_columns, non_integer_columns = identify_integer_columns(x_train_cleaned)\n",
    "\n",
    "assert len(integer_columns) + len(non_integer_columns) == x_train_cleaned.shape[1]\n",
    "\n",
    "\n",
    "# Print the integer columns\n",
    "print(f\"Number of columns containing only integer values: {len(integer_columns)}\")\n",
    "\n",
    "# Count the number of columns in integer_columns that contain at least one zero\n",
    "num_columns_with_zero = sum(np.any(x_train_cleaned[:, col] == 0) for col in integer_columns)\n",
    "\n",
    "# Print the result\n",
    "print(f\"Percentage of integer columns that contain at least one zero: {num_columns_with_zero/len(integer_columns)*100:.2f}%\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(If only contains integers and no zeroes (=encoded), encode Nan as 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 9 has been encoded with NaNs as the mode 1.0\n",
      "Column 10 has been encoded with NaNs as the mode 1.0\n",
      "Column 11 has been encoded with NaNs as the mode 1.0\n",
      "Column 12 has been encoded with NaNs as the mode 2.0\n",
      "Column 13 has been encoded with NaNs as the mode 2.0\n",
      "Column 14 has been encoded with NaNs as the mode 1.0\n",
      "Column 15 has been encoded with NaNs as the mode 1.0\n",
      "Column 16 has been encoded with NaNs as the mode 1.0\n",
      "Column 17 has been encoded with NaNs as the mode 1.0\n",
      "Column 18 has been encoded with NaNs as the mode 2.0\n",
      "Column 19 has been encoded with NaNs as the mode 1.0\n",
      "Column 20 has been encoded with NaNs as the mode 1.0\n",
      "Column 21 has been encoded with NaNs as the mode 2.0\n",
      "Column 22 has been encoded with NaNs as the mode 2.0\n",
      "Column 23 has been encoded with NaNs as the mode 2.0\n",
      "Column 24 has been encoded with NaNs as the mode 88.0\n",
      "Column 26 has been encoded with NaNs as the mode 88.0\n",
      "Column 29 has been encoded with NaNs as the mode 2.0\n",
      "Column 30 has been encoded with NaNs as the mode 1.0\n",
      "Column 31 has been encoded with NaNs as the mode 3.0\n",
      "Column 32 has been encoded with NaNs as the mode 1.0\n",
      "Column 34 has been encoded with NaNs as the mode 1.0\n",
      "Column 35 has been encoded with NaNs as the mode 2.0\n",
      "Column 38 has been encoded with NaNs as the mode 2.0\n",
      "Column 41 has been encoded with NaNs as the mode 2.0\n",
      "Column 44 has been encoded with NaNs as the mode 3.0\n",
      "Column 49 has been encoded with NaNs as the mode 2.0\n",
      "Column 50 has been encoded with NaNs as the mode 1.0\n",
      "Column 51 has been encoded with NaNs as the mode 2.0\n",
      "Column 53 has been encoded with NaNs as the mode 88.0\n",
      "Column 54 has been encoded with NaNs as the mode 8.0\n",
      "Column 55 has been encoded with NaNs as the mode 1.0\n",
      "Column 56 has been encoded with NaNs as the mode 200.0\n",
      "Column 57 has been encoded with NaNs as the mode 504.0\n",
      "Column 58 has been encoded with NaNs as the mode 2.0\n",
      "Column 59 has been encoded with NaNs as the mode 2.0\n",
      "Column 60 has been encoded with NaNs as the mode 2.0\n",
      "Column 61 has been encoded with NaNs as the mode 2.0\n",
      "Column 62 has been encoded with NaNs as the mode 2.0\n",
      "Column 63 has been encoded with NaNs as the mode 2.0\n",
      "Column 64 has been encoded with NaNs as the mode 2.0\n",
      "Column 65 has been encoded with NaNs as the mode 2.0\n",
      "Column 66 has been encoded with NaNs as the mode 3.0\n",
      "Column 67 has been encoded with NaNs as the mode 7.0\n",
      "Column 68 has been encoded with NaNs as the mode 3.0\n",
      "Column 69 has been encoded with NaNs as the mode 888.0\n",
      "Column 70 has been encoded with NaNs as the mode 1.0\n",
      "Column 71 has been encoded with NaNs as the mode 88.0\n",
      "Column 72 has been encoded with NaNs as the mode 2.0\n",
      "Column 73 has been encoded with NaNs as the mode 555.0\n",
      "Column 74 has been encoded with NaNs as the mode 101.0\n",
      "Column 75 has been encoded with NaNs as the mode 555.0\n",
      "Column 76 has been encoded with NaNs as the mode 101.0\n",
      "Column 77 has been encoded with NaNs as the mode 555.0\n",
      "Column 78 has been encoded with NaNs as the mode 101.0\n",
      "Column 79 has been encoded with NaNs as the mode 1.0\n",
      "Column 80 has been encoded with NaNs as the mode 64.0\n",
      "Column 81 has been encoded with NaNs as the mode 103.0\n",
      "Column 82 has been encoded with NaNs as the mode 30.0\n",
      "Column 83 has been encoded with NaNs as the mode 88.0\n",
      "Column 84 has been encoded with NaNs as the mode 102.0\n",
      "Column 85 has been encoded with NaNs as the mode 30.0\n",
      "Column 86 has been encoded with NaNs as the mode 888.0\n",
      "Column 87 has been encoded with NaNs as the mode 2.0\n",
      "Column 88 has been encoded with NaNs as the mode 2.0\n",
      "Column 89 has been encoded with NaNs as the mode 3.0\n",
      "Column 90 has been encoded with NaNs as the mode 5.0\n",
      "Column 91 has been encoded with NaNs as the mode 1.0\n",
      "Column 92 has been encoded with NaNs as the mode 2.0\n",
      "Column 93 has been encoded with NaNs as the mode 102014.0\n",
      "Column 94 has been encoded with NaNs as the mode 1.0\n",
      "Column 95 has been encoded with NaNs as the mode 2.0\n",
      "Column 96 has been encoded with NaNs as the mode 2.0\n",
      "Column 97 has been encoded with NaNs as the mode 777777.0\n",
      "Column 98 has been encoded with NaNs as the mode 1.0\n",
      "Column 99 has been encoded with NaNs as the mode 2.0\n",
      "Column 100 has been encoded with NaNs as the mode 2.0\n",
      "Column 101 has been encoded with NaNs as the mode 1.0\n",
      "Column 102 has been encoded with NaNs as the mode 4.0\n",
      "Column 104 has been encoded with NaNs as the mode 1.0\n",
      "Column 105 has been encoded with NaNs as the mode 1.0\n",
      "Column 110 has been encoded with NaNs as the mode 9.0\n",
      "Column 118 has been encoded with NaNs as the mode 1.0\n",
      "Column 122 has been encoded with NaNs as the mode 2.0\n",
      "Column 129 has been encoded with NaNs as the mode 1.0\n",
      "Column 134 has been encoded with NaNs as the mode 64.0\n",
      "Column 138 has been encoded with NaNs as the mode 3.0\n",
      "Column 173 has been encoded with NaNs as the mode 1.0\n",
      "Column 174 has been encoded with NaNs as the mode 0.0\n",
      "Column 175 has been encoded with NaNs as the mode 30.0\n",
      "Column 176 has been encoded with NaNs as the mode 30.0\n",
      "Column 179 has been encoded with NaNs as the mode 180.0\n",
      "Column 180 has been encoded with NaNs as the mode 0.0\n",
      "Column 183 has been encoded with NaNs as the mode 0.0\n",
      "Column 184 has been encoded with NaNs as the mode 0.0\n",
      "Column 185 has been encoded with NaNs as the mode 180.0\n",
      "Column 186 has been encoded with NaNs as the mode 0.0\n",
      "Column 187 has been encoded with NaNs as the mode 0.0\n",
      "Column 188 has been encoded with NaNs as the mode 0.0\n",
      "Column 197 has been encoded with NaNs as the mode 3.0\n",
      "Column 198 has been encoded with NaNs as the mode 3.0\n",
      "Column 199 has been encoded with NaNs as the mode 4.0\n",
      "Column 202 has been encoded with NaNs as the mode 1.0\n",
      "Column 203 has been encoded with NaNs as the mode 1.0\n",
      "Column 204 has been encoded with NaNs as the mode 2.0\n",
      "Number of integer columns encoded: 105\n",
      "Column 107 has been encoded with NaNs as the binned mode 8.956952611387733\n",
      "Column 112 has been encoded with NaNs as the binned mode 0.7649543617619013\n",
      "Column 135 has been encoded with NaNs as the binned mode 1.6375\n",
      "Column 136 has been encoded with NaNs as the binned mode 66.76304999999999\n",
      "Column 137 has been encoded with NaNs as the binned mode 26.14895\n",
      "Column 150 has been encoded with NaNs as the binned mode 0.495\n",
      "Column 151 has been encoded with NaNs as the binned mode 0.495\n",
      "Column 152 has been encoded with NaNs as the binned mode 0.495\n",
      "Column 153 has been encoded with NaNs as the binned mode 0.495\n",
      "Column 154 has been encoded with NaNs as the binned mode 0.495\n",
      "Column 155 has been encoded with NaNs as the binned mode 0.495\n",
      "Column 160 has been encoded with NaNs as the binned mode 0.75\n",
      "Column 161 has been encoded with NaNs as the binned mode 0.99645\n",
      "Column 169 has been encoded with NaNs as the binned mode 3.52\n",
      "Column 170 has been encoded with NaNs as the binned mode 0.064\n",
      "Column 177 has been encoded with NaNs as the binned mode 2.7021749999999995\n",
      "Column 178 has been encoded with NaNs as the binned mode 0.726835\n",
      "Column 181 has been encoded with NaNs as the binned mode 0.495\n",
      "Number of non integer columns encoded: 18\n",
      "Column 9 has been encoded with NaNs as the mode 1.0\n",
      "Column 10 has been encoded with NaNs as the mode 1.0\n",
      "Column 11 has been encoded with NaNs as the mode 1.0\n",
      "Column 12 has been encoded with NaNs as the mode 2.0\n",
      "Column 13 has been encoded with NaNs as the mode 2.0\n",
      "Column 14 has been encoded with NaNs as the mode 1.0\n",
      "Column 15 has been encoded with NaNs as the mode 1.0\n",
      "Column 16 has been encoded with NaNs as the mode 1.0\n",
      "Column 17 has been encoded with NaNs as the mode 1.0\n",
      "Column 18 has been encoded with NaNs as the mode 2.0\n",
      "Column 19 has been encoded with NaNs as the mode 1.0\n",
      "Column 20 has been encoded with NaNs as the mode 1.0\n",
      "Column 21 has been encoded with NaNs as the mode 2.0\n",
      "Column 22 has been encoded with NaNs as the mode 2.0\n",
      "Column 26 has been encoded with NaNs as the mode 88.0\n",
      "Column 32 has been encoded with NaNs as the mode 1.0\n",
      "Column 34 has been encoded with NaNs as the mode 1.0\n",
      "Column 35 has been encoded with NaNs as the mode 2.0\n",
      "Column 44 has been encoded with NaNs as the mode 3.0\n",
      "Column 49 has been encoded with NaNs as the mode 2.0\n",
      "Column 50 has been encoded with NaNs as the mode 1.0\n",
      "Column 51 has been encoded with NaNs as the mode 2.0\n",
      "Column 53 has been encoded with NaNs as the mode 88.0\n",
      "Column 54 has been encoded with NaNs as the mode 8.0\n",
      "Column 55 has been encoded with NaNs as the mode 1.0\n",
      "Column 56 has been encoded with NaNs as the mode 200.0\n",
      "Column 57 has been encoded with NaNs as the mode 506.0\n",
      "Column 58 has been encoded with NaNs as the mode 2.0\n",
      "Column 59 has been encoded with NaNs as the mode 2.0\n",
      "Column 60 has been encoded with NaNs as the mode 2.0\n",
      "Column 61 has been encoded with NaNs as the mode 2.0\n",
      "Column 62 has been encoded with NaNs as the mode 2.0\n",
      "Column 63 has been encoded with NaNs as the mode 2.0\n",
      "Column 64 has been encoded with NaNs as the mode 2.0\n",
      "Column 65 has been encoded with NaNs as the mode 2.0\n",
      "Column 66 has been encoded with NaNs as the mode 3.0\n",
      "Column 67 has been encoded with NaNs as the mode 7.0\n",
      "Column 68 has been encoded with NaNs as the mode 3.0\n",
      "Column 69 has been encoded with NaNs as the mode 888.0\n",
      "Column 70 has been encoded with NaNs as the mode 1.0\n",
      "Column 71 has been encoded with NaNs as the mode 88.0\n",
      "Column 72 has been encoded with NaNs as the mode 1.0\n",
      "Column 73 has been encoded with NaNs as the mode 555.0\n",
      "Column 74 has been encoded with NaNs as the mode 101.0\n",
      "Column 75 has been encoded with NaNs as the mode 555.0\n",
      "Column 76 has been encoded with NaNs as the mode 101.0\n",
      "Column 77 has been encoded with NaNs as the mode 555.0\n",
      "Column 78 has been encoded with NaNs as the mode 101.0\n",
      "Column 79 has been encoded with NaNs as the mode 1.0\n",
      "Column 80 has been encoded with NaNs as the mode 64.0\n",
      "Column 81 has been encoded with NaNs as the mode 103.0\n",
      "Column 82 has been encoded with NaNs as the mode 30.0\n",
      "Column 83 has been encoded with NaNs as the mode 88.0\n",
      "Column 84 has been encoded with NaNs as the mode 102.0\n",
      "Column 85 has been encoded with NaNs as the mode 100.0\n",
      "Column 86 has been encoded with NaNs as the mode 888.0\n",
      "Column 87 has been encoded with NaNs as the mode 2.0\n",
      "Column 88 has been encoded with NaNs as the mode 2.0\n",
      "Column 89 has been encoded with NaNs as the mode 3.0\n",
      "Column 90 has been encoded with NaNs as the mode 5.0\n",
      "Column 91 has been encoded with NaNs as the mode 1.0\n",
      "Column 92 has been encoded with NaNs as the mode 2.0\n",
      "Column 93 has been encoded with NaNs as the mode 102014.0\n",
      "Column 94 has been encoded with NaNs as the mode 1.0\n",
      "Column 95 has been encoded with NaNs as the mode 2.0\n",
      "Column 96 has been encoded with NaNs as the mode 2.0\n",
      "Column 97 has been encoded with NaNs as the mode 777777.0\n",
      "Column 98 has been encoded with NaNs as the mode 1.0\n",
      "Column 99 has been encoded with NaNs as the mode 2.0\n",
      "Column 100 has been encoded with NaNs as the mode 2.0\n",
      "Column 101 has been encoded with NaNs as the mode 1.0\n",
      "Column 102 has been encoded with NaNs as the mode 4.0\n",
      "Column 104 has been encoded with NaNs as the mode 1.0\n",
      "Column 105 has been encoded with NaNs as the mode 1.0\n",
      "Column 110 has been encoded with NaNs as the mode 9.0\n",
      "Column 118 has been encoded with NaNs as the mode 1.0\n",
      "Column 122 has been encoded with NaNs as the mode 2.0\n",
      "Column 129 has been encoded with NaNs as the mode 1.0\n",
      "Column 134 has been encoded with NaNs as the mode 66.0\n",
      "Column 138 has been encoded with NaNs as the mode 3.0\n",
      "Column 173 has been encoded with NaNs as the mode 1.0\n",
      "Column 174 has been encoded with NaNs as the mode 0.0\n",
      "Column 175 has been encoded with NaNs as the mode 30.0\n",
      "Column 176 has been encoded with NaNs as the mode 60.0\n",
      "Column 179 has been encoded with NaNs as the mode 180.0\n",
      "Column 180 has been encoded with NaNs as the mode 0.0\n",
      "Column 183 has been encoded with NaNs as the mode 0.0\n",
      "Column 184 has been encoded with NaNs as the mode 0.0\n",
      "Column 185 has been encoded with NaNs as the mode 180.0\n",
      "Column 186 has been encoded with NaNs as the mode 0.0\n",
      "Column 187 has been encoded with NaNs as the mode 0.0\n",
      "Column 188 has been encoded with NaNs as the mode 0.0\n",
      "Column 197 has been encoded with NaNs as the mode 3.0\n",
      "Column 198 has been encoded with NaNs as the mode 3.0\n",
      "Column 199 has been encoded with NaNs as the mode 4.0\n",
      "Column 202 has been encoded with NaNs as the mode 1.0\n",
      "Column 203 has been encoded with NaNs as the mode 1.0\n",
      "Column 204 has been encoded with NaNs as the mode 2.0\n",
      "Number of integer columns encoded: 98\n",
      "Column 107 has been encoded with NaNs as the binned mode 8.956952611387733\n",
      "Column 112 has been encoded with NaNs as the binned mode 0.68925311554367\n",
      "Column 135 has been encoded with NaNs as the binned mode 1.6835\n",
      "Column 136 has been encoded with NaNs as the binned mode 69.16865000000001\n",
      "Column 137 has been encoded with NaNs as the binned mode 26.845750000000002\n",
      "Column 150 has been encoded with NaNs as the binned mode 0.15\n",
      "Column 151 has been encoded with NaNs as the binned mode 0.495\n",
      "Column 152 has been encoded with NaNs as the binned mode 0.175\n",
      "Column 153 has been encoded with NaNs as the binned mode 0.15\n",
      "Column 154 has been encoded with NaNs as the binned mode 0.125\n",
      "Column 155 has been encoded with NaNs as the binned mode 0.495\n",
      "Column 160 has been encoded with NaNs as the binned mode 0.5\n",
      "Column 161 has been encoded with NaNs as the binned mode 1.5115500000000002\n",
      "Column 169 has been encoded with NaNs as the binned mode 3.52\n",
      "Column 170 has been encoded with NaNs as the binned mode 0.064\n",
      "Column 177 has been encoded with NaNs as the binned mode 2.7021749999999995\n",
      "Column 178 has been encoded with NaNs as the binned mode 0.726835\n",
      "Column 181 has been encoded with NaNs as the binned mode 0.495\n",
      "Number of non integer columns encoded: 18\n"
     ]
    }
   ],
   "source": [
    "x_train_cleaned_without_nans = encode_nan_integer_columns(x_train_cleaned, replacement_value='mode')\n",
    "x_train_cleaned_without_nans = encode_nan_continuous_columns(x_train_cleaned_without_nans, replacement_value='mode')\n",
    "\n",
    "assert np.isnan(x_train_cleaned_without_nans).sum() == 0\n",
    "assert x_train_cleaned.shape == x_train_cleaned_without_nans.shape\n",
    "\n",
    "adapted_x_test_without_nans = encode_nan_integer_columns(adapted_x_test, replacement_value='mode')\n",
    "adapted_x_test_without_nans = encode_nan_continuous_columns(adapted_x_test_without_nans, replacement_value='mode')\n",
    "\n",
    "assert np.isnan(adapted_x_test_without_nans).sum() == 0\n",
    "assert adapted_x_test.shape == adapted_x_test_without_nans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of columns that do not contain only integer values\n",
    "num_non_integer_columns = len(non_integer_columns)\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of columns that do not contain only integer values: {num_non_integer_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In columns containing only integer values, number of unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "unique_value_counts = np.array([len(np.unique(x_train_cleaned[:, col])) for col in integer_columns])\n",
    "\n",
    "# Create 20 bins based on the range of unique value counts\n",
    "max_unique = unique_value_counts.max() if unique_value_counts.size > 0 else 0\n",
    "bins = np.linspace(0, max_unique, 21)  # 21 edges for 20 bins\n",
    "bin_labels = [f'{int(b)}-{int(bins[i+1])}' for i, b in enumerate(bins[:-1])]\n",
    "\n",
    "# Count how many columns fall into each bin\n",
    "binned_counts = np.histogram(unique_value_counts, bins=bins)[0]\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(bin_labels, binned_counts, width=0.6, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Number of Unique Values in Columns')\n",
    "plt.ylabel('Number of Columns')\n",
    "plt.title('Columns Grouped by Number of Unique Values (20 Bins)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "# Create the second set of bins for values between 2000 and 0\n",
    "bins_2000 = np.linspace(0, 2000, 21)  # 21 edges for 20 bins\n",
    "bin_labels_2000 = [f'{int(b)}-{int(bins_2000[i+1])}' for i, b in enumerate(bins_2000[:-1])]\n",
    "\n",
    "# Count how many columns fall into each bin for the second set of bins\n",
    "binned_counts_2000 = np.histogram(unique_value_counts, bins=bins_2000)[0]\n",
    "\n",
    "# Create the second bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(bin_labels_2000, binned_counts_2000, width=0.6, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Number of Unique Values in Columns (0-2000)')\n",
    "plt.ylabel('Number of Columns')\n",
    "plt.title('Columns Grouped by Number of Unique Values (20 Bins, 0-2000)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Create the third set of bins for values between 0 and 100\n",
    "bins_100 = np.linspace(0, 100, 21)  # 21 edges for 20 bins\n",
    "bin_labels_100 = [f'{int(b)}-{int(bins_100[i+1])}' for i, b in enumerate(bins_100[:-1])]\n",
    "\n",
    "# Count how many columns fall into each bin for the third set of bins\n",
    "binned_counts_100 = np.histogram(unique_value_counts, bins=bins_100)[0]\n",
    "\n",
    "# Create the third bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(bin_labels_100, binned_counts_100, width=0.6, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Number of Unique Values in Columns (0-100)')\n",
    "plt.ylabel('Number of Columns')\n",
    "plt.title('Columns Grouped by Number of Unique Values (20 Bins, 0-100)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given number of unique value mainly in 0-5 range, lets say it's categorical if in this range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_threshold = 5\n",
    "\n",
    "# Step 1: Compute unique value counts for each integer column\n",
    "unique_value_counts = np.array([len(np.unique(x_train_cleaned[:, col])) for col in integer_columns])\n",
    "\n",
    "# Step 2: Identify categorical and non-categorical features based on the threshold\n",
    "indexes_categorical_features = [integer_columns[i] for i, count in enumerate(unique_value_counts) if count <= categorical_threshold]\n",
    "indexes_non_categorical_features = [integer_columns[i] for i in range(len(unique_value_counts)) if integer_columns[i] not in indexes_categorical_features]\n",
    "\n",
    "assert len(indexes_categorical_features) + len(indexes_non_categorical_features) == len(unique_value_counts)\n",
    "assert unique_value_counts.size == len(integer_columns)\n",
    "\n",
    "indexes_non_categorical_features.extend(non_integer_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_standardized = standardize_columns(x_train_cleaned_without_nans, range(x_train_cleaned_without_nans.shape[1]))\n",
    "\n",
    "x_standardized = standardize_columns(x_train_cleaned_without_nans, indexes_non_categorical_features)\n",
    "\n",
    "x_test_standardized = standardize_columns(adapted_x_test_without_nans, indexes_non_categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_x_train = binary_encode_columns(x_standardized, indexes_categorical_features)\n",
    "\n",
    "encoded_x_train, encoded_x_test = consistent_binary_encode(x_standardized, x_test_standardized, indexes_categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 291)\n",
      "(109379, 291)\n"
     ]
    }
   ],
   "source": [
    "print(encoded_x_train.shape)\n",
    "print(encoded_x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding best parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/29: loss=0.28796094552037377, w0=3.1937394486283e-05, w1=3.7822689140182695e-05\n",
      "GD iter. 1/29: loss=0.20462583590895084, w0=6.483885073931895e-05, w1=6.815606421484738e-05\n",
      "GD iter. 2/29: loss=0.1715095077404318, w0=9.759493856512131e-05, w1=9.357042566203736e-05\n",
      "GD iter. 3/29: loss=0.15803033802969904, w0=0.0001295640075152702, w1=0.00011566807066494498\n",
      "GD iter. 4/29: loss=0.15226677786053286, w0=0.00016039281271903623, w1=0.0001354483363872032\n",
      "GD iter. 5/29: loss=0.14956674532952566, w0=0.00018990481312281468, w1=0.0001535352914066538\n",
      "GD iter. 6/29: loss=0.1481107782823617, w0=0.00021803068712045306, w1=0.00017031971736389262\n",
      "GD iter. 7/29: loss=0.14718371744570138, w0=0.0002447651802468456, w1=0.00018604760974367428\n",
      "GD iter. 8/29: loss=0.1465013895658475, w0=0.0002701403719804014, w1=0.00020087531103884037\n",
      "GD iter. 9/29: loss=0.1459482336374731, w0=0.0002942091759896229, w1=0.00021490382820801737\n",
      "GD iter. 10/29: loss=0.1454750060478609, w0=0.0003170352142943987, w1=0.00022820016735820264\n",
      "GD iter. 11/29: loss=0.14505885031837876, w0=0.0003386866574907088, w1=0.00024081057351811692\n",
      "GD iter. 12/29: loss=0.14468766965178187, w0=0.0003592325291202086, w1=0.0002527687254013052\n",
      "GD iter. 13/29: loss=0.14435397554589674, w0=0.0003787405376028273, w1=0.0002641007880286688\n",
      "GD iter. 14/29: loss=0.14405243605788673, w0=0.0003972758519246746, w1=0.0002748285102622013\n",
      "GD iter. 15/29: loss=0.14377887261176275, w0=0.0004149004573908757, w1=0.0002849711076000621\n",
      "GD iter. 16/29: loss=0.14352982751824056, w0=0.0004316728650823996, w1=0.000294546391834148\n",
      "GD iter. 17/29: loss=0.14330235940900465, w0=0.00044764803432057056, w1=0.00030357143523897457\n",
      "GD iter. 18/29: loss=0.14309393230369397, w0=0.00046287742086646233, w1=0.00031206294844185445\n",
      "GD iter. 19/29: loss=0.1429023453488546, w0=0.0004774090968869361, w1=0.00032003748342772766\n",
      "GD iter. 20/29: loss=0.14272568203210292, w0=0.0004912879094699518, w1=0.00032751153091028535\n",
      "GD iter. 21/29: loss=0.14256227012403408, w0=0.0005045556573902703, w1=0.0003345015549761195\n",
      "GD iter. 22/29: loss=0.1424106485161055, w0=0.0005172512738591898, w1=0.000341023991502996\n",
      "GD iter. 23/29: loss=0.14226953909498888, w0=0.0005294110079772117, w1=0.00034709522663653133\n",
      "GD iter. 24/29: loss=0.14213782261185576, w0=0.000541068600693923, w1=0.0003527315652535212\n",
      "GD iter. 25/29: loss=0.14201451786666364, w0=0.000552255452980844, w1=0.00035794919539209566\n",
      "GD iter. 26/29: loss=0.14189876370551802, w0=0.0005630007850872584, w1=0.000362764152182203\n",
      "GD iter. 27/29: loss=0.14178980343062972, w0=0.000573331786454751, w1=0.00036719228329892606\n",
      "GD iter. 28/29: loss=0.14168697128965438, w0=0.0005832737562871857, w1=0.00037124921703289435\n",
      "GD iter. 29/29: loss=0.14158968076138284, w0=0.0005928502350174836, w1=0.0003749503335063564\n"
     ]
    }
   ],
   "source": [
    "# X_ici = x_train_cleaned_without_nans\n",
    "# X_ici = standardize_columns(X_ici, indexes_non_categorical_features)\n",
    "\n",
    "X_ici = encoded_x_train\n",
    "\n",
    "# # X_ici = x_train_cleaned\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_ici = y_train\n",
    "\n",
    "# linear regression\n",
    "initial_w = np.zeros(X_ici.shape[1])\n",
    "max_iters = 30\n",
    "gamma = 0.01\n",
    "# print (least_squares(y_ici, X_ici))\n",
    "w, loss = mean_squared_error_gd(y_ici, X_ici, initial_w, max_iters, gamma)\n",
    "\n",
    "# percentages_to_drop = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "# nan_values_for_integer_columns = ['mode', 'upper', 'zero']\n",
    "# nan_values_for_continuous_columns = ['mean', 'mode', 'zero']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 ... -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "from predict_labels import *\n",
    "# adapted_x_test = np.delete(x_test, deleted_indices, axis=1)\n",
    "# standardized_x_test = standardize_columns(adapted_x_test, indexes_non_categorical_features)\n",
    "# encoded_x_test = binary_encode_columns(adapted_x_test, indexes_categorical_features)\n",
    "# print(standardized_x_test.shape)\n",
    "# print(x_standardized.shape)\n",
    "\n",
    "# print(encoded_x_test.shape)\n",
    "# print(encoded_x_train.shape)\n",
    "y_test = predict_classification(encoded_x_test,w)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "percentage of Nan to drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = np.inf\n",
    "best_percentage_to_drop = None\n",
    "best_nan_value_for_integer_columns = None\n",
    "best_nan_value_for_continuous_columns = None\n",
    "\n",
    "for percentage_to_drop in percentages_to_drop:\n",
    "    for nan_value_for_continuous_columns in nan_values_for_continuous_columns:\n",
    "        for nan_value_for_integer_columns in nan_values_for_integer_columns:\n",
    "    \n",
    "            x_train_cleaned = remove_nan_features(x_train, percentage_to_drop)\n",
    "\n",
    "            x_train_cleaned_without_nans = encode_nan_integer_columns(x_train_cleaned, replacement_value=nan_value_for_integer_columns)\n",
    "            x_train_cleaned_without_nans = encode_nan_continuous_columns(x_train_cleaned_without_nans, replacement_value=nan_value_for_continuous_columns)\n",
    "\n",
    "            assert np.isnan(x_train_cleaned_without_nans).sum() == 0\n",
    "            assert x_train_cleaned.shape == x_train_cleaned_without_nans.shape\n",
    "\n",
    "            x_standardized = standardize_columns(x_train_cleaned_without_nans, range(x_train_cleaned_without_nans.shape[1]))\n",
    "\n",
    "            initial_w = np.zeros(X_ici.shape[1])\n",
    "            max_iters = 100\n",
    "            gamma = 0.01\n",
    "\n",
    "            w, loss = mean_squared_error_gd(y_ici, X_ici, initial_w, max_iters, gamma)\n",
    "\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_percentage_to_drop = percentage_to_drop\n",
    "                best_nan_value_for_integer_columns = nan_value_for_integer_columns\n",
    "                best_nan_value_for_continuous_columns = nan_value_for_continuous_columns\n",
    "\n",
    "print(f\"Best loss: {best_loss}\")    \n",
    "print(f\"Best percentage to drop: {best_percentage_to_drop}\")\n",
    "print(f\"Best nan value for integer columns: {best_nan_value_for_integer_columns}\")\n",
    "print(f\"Best nan value for continuous columns: {best_nan_value_for_continuous_columns}\")\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
