{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "from crossvalidation import *\n",
    "import os\n",
    "from helpers import *\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "/Users/louistschanz/Documents/EPFL/MA1/ML/Project 1/ml-project-1-ai-huasca-1/dataset/y_train.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Loading the data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#data_path = os.path.join(os.getcwd(), \"dataset\")\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# or\u001b[39;00m\n\u001b[1;32m      4\u001b[0m data_path \u001b[38;5;241m=\u001b[39m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/louistschanz/Documents/EPFL/MA1/ML/Project 1/ml-project-1-ai-huasca-1/dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m x_train, x_test, y_train, train_ids, test_ids \u001b[38;5;241m=\u001b[39m \u001b[43mload_csv_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData loaded successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Basic settings for reproducibility\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/EPFL/MA1/ML/Project 1/ml-project-1-ai-huasca-1/helpers.py:24\u001b[0m, in \u001b[0;36mload_csv_data\u001b[0;34m(data_path, sub_sample)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_csv_data\u001b[39m(data_path, sub_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m    This function loads the data and returns the respectinve numpy arrays.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    Remember to put the 3 files in the same folder and to not change the names of the files.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m        test_ids (np.array): ids of test data\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenfromtxt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_train.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     x_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mgenfromtxt(\n\u001b[1;32m     32\u001b[0m         os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, skip_header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     33\u001b[0m     )\n\u001b[1;32m     34\u001b[0m     x_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mgenfromtxt(\n\u001b[1;32m     35\u001b[0m         os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, skip_header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     36\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/MLCourse/lib/python3.10/site-packages/numpy/lib/npyio.py:1980\u001b[0m, in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, ndmin, like)\u001b[0m\n\u001b[1;32m   1978\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os_fspath(fname)\n\u001b[1;32m   1979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m-> 1980\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datasource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1981\u001b[0m     fid_ctx \u001b[38;5;241m=\u001b[39m contextlib\u001b[38;5;241m.\u001b[39mclosing(fid)\n\u001b[1;32m   1982\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/MLCourse/lib/python3.10/site-packages/numpy/lib/_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m \n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m ds \u001b[38;5;241m=\u001b[39m DataSource(destpath)\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/MLCourse/lib/python3.10/site-packages/numpy/lib/_datasource.py:533\u001b[0m, in \u001b[0;36mDataSource.open\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    531\u001b[0m                               encoding\u001b[38;5;241m=\u001b[39mencoding, newline\u001b[38;5;241m=\u001b[39mnewline)\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: /Users/louistschanz/Documents/EPFL/MA1/ML/Project 1/ml-project-1-ai-huasca-1/dataset/y_train.csv not found."
     ]
    }
   ],
   "source": [
    "# Loading the data\n",
    "#data_path = os.path.join(os.getcwd(), \"dataset\")\n",
    "# or\n",
    "data_path = data_path = \"/Users/louistschanz/Documents/EPFL/MA1/ML/Project 1/ml-project-1-ai-huasca-1/dataset\"\n",
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(data_path)\n",
    "print(\"Data loaded successfully!\")\n",
    "\n",
    "# Basic settings for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Models and Hyperparameter Grids\n",
    "# Dictionary of model functions\n",
    "models = {\n",
    "    \"mean_squared_error_gd\": mean_squared_error_gd,\n",
    "    \"mean_squared_error_sgd\": mean_squared_error_sgd,\n",
    "    \"least_squares\": least_squares,\n",
    "    \"ridge_regression\": ridge_regression,\n",
    "    \"logistic_regression\": logistic_regression,\n",
    "    \"reg_logistic_regression\": reg_logistic_regression\n",
    "}\n",
    "\n",
    "# Define hyperparameter grids for each model\n",
    "param_grid = {\n",
    "    \"mean_squared_error_gd\": {\"initial_w\": [np.zeros(x_train.shape[1])], \"max_iters\": [500, 1000], \"gamma\": [0.01, 0.1, 0.5]},\n",
    "    \"mean_squared_error_sgd\": {\"initial_w\": [np.zeros(x_train.shape[1])], \"max_iters\": [500, 1000], \"gamma\": [0.01, 0.1, 0.5]},\n",
    "    \"least_squares\": {},  # No hyperparameter for least squares\n",
    "    \"ridge_regression\": {\"lambda_\": [0.01, 0.1, 1, 10]},\n",
    "    \"logistic_regression\": {\"initial_w\": [np.zeros(x_train.shape[1])], \"max_iters\": [500, 1000], \"gamma\": [0.01, 0.1, 0.5]},\n",
    "    \"reg_logistic_regression\": {\"initial_w\": [np.zeros(x_train.shape[1])], \"max_iters\": [500, 1000], \"gamma\": [0.01, 0.1, 0.5], \"lambda_\": [0.01, 0.1, 1, 10]} # lambda only for reg_logistic_regression\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validate and tune hyperparameters for each model\n",
    "# Dictionary to store best parameters and scores for each model\n",
    "tuning_results = {}\n",
    "\n",
    "# Loop through each model for cross-validation and tuning\n",
    "for model_name, model_fn in models.items():\n",
    "    print(f\"\\nCross-validating and tuning {model_name}...\")\n",
    "    \n",
    "    # Retrieve hyperparameters for the current model\n",
    "    model_params = param_grid[model_name]\n",
    "    \n",
    "    best_score = float('inf')\n",
    "    best_params = None\n",
    "    scores = []  # Store scores for plotting\n",
    "\n",
    "    # Perform grid search over hyperparameter combinations\n",
    "    param_names, param_values = zip(*model_params.items())\n",
    "    for param_combo in product(*param_values):\n",
    "        params = dict(zip(param_names, param_combo))\n",
    "        \n",
    "        # Cross-validate with the current parameter combination\n",
    "        cv_score = cross_validate(model_fn, X=x_train, y=y_train, k=5, **params)\n",
    "        scores.append((params, cv_score))\n",
    "        print(f\"Params: {params}, Cross-validated loss: {cv_score}\")\n",
    "        \n",
    "        # Update best score and parameters if current score is better\n",
    "        if cv_score < best_score:\n",
    "            best_score = cv_score\n",
    "            best_params = params\n",
    "    \n",
    "    # Store the best result for the current model\n",
    "    tuning_results[model_name] = {\"best_params\": best_params, \"best_score\": best_score, \"scores\": scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code que j'avais fais avant qd c'était dans le run, \n",
    "# mtn méthode differente, car run de crossvalidation dans le notebook crossvalidation\n",
    "\n",
    "\n",
    "# ***************** Cross validation ***************** #\n",
    "\n",
    "# Flexible crossvalidation on which function from implementations you want to validate\n",
    "# there are dynamical arguments and you can change the function you want to validate by changing the function name\n",
    "\n",
    "# 0) define the parameters\n",
    "initial_w = np.zeros(x_train.shape[1])  # Initial weights\n",
    "max_iters = 1000                       # Number of iterations\n",
    "gamma = 0.1                             # Learning rate\n",
    "lambda_ = 0.1                           # Regularization parameter\n",
    "\n",
    "# 1) mean_squared_error_gd\n",
    "cv_loss_gd = cross_validate(model_fn=mean_squared_error_gd, X=x_train, Y=y_train, k=5, initial_w=initial_w, max_iters=max_iters, gamma=gamma)\n",
    "print(\"Cross-validated loss for mean_squared_error_gd:\", cv_loss_gd)\n",
    "\n",
    "# 2) mean_squared_error_sgd\n",
    "cv_loss_sgd = cross_validate(model_fn=mean_squared_error_sgd, X=x_train, Y=y_train, k=5, initial_w=initial_w, max_iters=max_iters, gamma=gamma)\n",
    "print(\"Cross-validated loss for mean_squared_error_sgd:\", cv_loss_gd)\n",
    "\n",
    "# 3) least_squares\n",
    "cv_loss_ls = cross_validate(model_fn=least_squares, X=x_train, Y=y_train, k=5)\n",
    "print(\"Cross-validated loss for least_squares:\", cv_loss_ls)\n",
    "\n",
    "# 4) ridge_regression\n",
    "#lambda_ = 0.1\n",
    "#cv_loss_rr = cross_validate(ridge_regression, X=x_train, Y=y_train, k=5, lambda_=lambda_)\n",
    "#print(\"Cross-validated loss for ridge_regression:\", cv_loss_rr)\n",
    "\n",
    "# 5) logistic_regression\n",
    "cv_loss_lr = cross_validate(\n",
    "    model_fn=logistic_regression,  # Pass the logistic regression function\n",
    "    X=x_train,\n",
    "    y=y_train,\n",
    "    k=5,\n",
    "    initial_w=initial_w,\n",
    "    max_iters=max_iters,\n",
    "    gamma=gamma\n",
    "    )\n",
    "print(\"Cross-validated loss for logistic_regression:\", cv_loss_lr)\n",
    "\n",
    "# 6) reg_logistic_regression\n",
    "cv_loss_rlr = cross_validate(\n",
    "    model_fn=reg_logistic_regression,  # Pass the regularized logistic regression function\n",
    "    X=x_train,\n",
    "    y=y_train,\n",
    "    k=5, initial_w=initial_w, max_iters=max_iters, gamma=gamma,lambda_=lambda_\n",
    ")\n",
    "print(\"Cross-validated loss for reg_logistic_regression:\", cv_loss_rlr)\n",
    "\n",
    "# 4) Ridge Regression : cross validate + fine tuning of parameters\n",
    "# Define ranges for hyperparameters\n",
    "gamma_values = [0.01, 0.1, 0.5]\n",
    "lambda_values = [0.01, 0.1, 1, 10]\n",
    "\n",
    "best_score = float('inf')\n",
    "best_params = {}\n",
    "\n",
    "# Perform grid search over gamma and lambda_\n",
    "for gamma in gamma_values:\n",
    "    for lambda_ in lambda_values:\n",
    "        cv_loss_rr = cross_validate(model_fn=ridge_regression,X=x_train,y=y_train,k=5,gamma=gamma,lambda_=lambda_)\n",
    "        print(f\"Cross-validated loss with gamma={gamma}, lambda_={lambda_}: {cv_loss_rr}\")\n",
    "        \n",
    "        # Update best score and parameters\n",
    "        if cv_loss_rr < best_score:\n",
    "            best_score = cv_loss_rr\n",
    "            best_params = {'gamma': gamma, 'lambda_': lambda_}\n",
    "\n",
    "print(f\"The best parameters: {best_params} yield a cross-validated loss of: {best_score}\")\n",
    "\n",
    "\n",
    "# LOOCV: To perform Leave-One-Out Cross-Validation --> just call cross_validate with k=len(y)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLCourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
