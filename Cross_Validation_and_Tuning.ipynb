{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "import os\n",
    "from helpers import *\n",
    "\n",
    "from crossvalidation import cross_validate\n",
    "from crossvalidation import tune_hyperparameters\n",
    "#from crossvalidation import tune_hyperparameters1\n",
    "#from crossvalidation import tune_hyperparameters2\n",
    "\n",
    "from helpers import *\n",
    "from helpers_perso import *\n",
    "from preprocessing.nan_imputation import *\n",
    "from preprocessing.one_hot_encoding import *\n",
    "from implementations import *\n",
    "from preprocessing.standardization import *\n",
    "from preprocessing.class_balancing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(os.getcwd(), \"data\", \"dataset\")\n",
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(data_path)\n",
    "print(\"Data loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST CODE\n",
    "# Create test arrays\n",
    "x_train = np.random.rand(150, 200)  # 25 x 25 array for features\n",
    "y_train = np.random.rand(150)   # 25 x 1 array for target values\n",
    "initial_weights = np.zeros(x_train.shape[1])  # Define initial weights based on feature count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of columns to delete (NaN proportion superior to 80.0 %): 36.14%\n",
      "Data cleaned successfully!\n",
      "Original shape of x_train: (328135, 321)\n",
      "Cleaned shape of x_train: (328135, 205)\n",
      "Column 9 has been encoded with NaNs as the mode 1.0\n",
      "Column 10 has been encoded with NaNs as the mode 1.0\n",
      "Column 11 has been encoded with NaNs as the mode 1.0\n",
      "Column 12 has been encoded with NaNs as the mode 2.0\n",
      "Column 13 has been encoded with NaNs as the mode 2.0\n",
      "Column 14 has been encoded with NaNs as the mode 1.0\n",
      "Column 15 has been encoded with NaNs as the mode 1.0\n",
      "Column 16 has been encoded with NaNs as the mode 1.0\n",
      "Column 17 has been encoded with NaNs as the mode 1.0\n",
      "Column 18 has been encoded with NaNs as the mode 2.0\n",
      "Column 19 has been encoded with NaNs as the mode 1.0\n",
      "Column 20 has been encoded with NaNs as the mode 1.0\n",
      "Column 21 has been encoded with NaNs as the mode 2.0\n",
      "Column 22 has been encoded with NaNs as the mode 2.0\n",
      "Column 23 has been encoded with NaNs as the mode 2.0\n",
      "Column 24 has been encoded with NaNs as the mode 88.0\n",
      "Column 26 has been encoded with NaNs as the mode 88.0\n",
      "Column 29 has been encoded with NaNs as the mode 2.0\n",
      "Column 30 has been encoded with NaNs as the mode 1.0\n",
      "Column 31 has been encoded with NaNs as the mode 3.0\n",
      "Column 32 has been encoded with NaNs as the mode 1.0\n",
      "Column 34 has been encoded with NaNs as the mode 1.0\n",
      "Column 35 has been encoded with NaNs as the mode 2.0\n",
      "Column 38 has been encoded with NaNs as the mode 2.0\n",
      "Column 41 has been encoded with NaNs as the mode 2.0\n",
      "Column 44 has been encoded with NaNs as the mode 3.0\n",
      "Column 49 has been encoded with NaNs as the mode 2.0\n",
      "Column 50 has been encoded with NaNs as the mode 1.0\n",
      "Column 51 has been encoded with NaNs as the mode 2.0\n",
      "Column 53 has been encoded with NaNs as the mode 88.0\n",
      "Column 54 has been encoded with NaNs as the mode 8.0\n",
      "Column 55 has been encoded with NaNs as the mode 1.0\n",
      "Column 56 has been encoded with NaNs as the mode 200.0\n",
      "Column 57 has been encoded with NaNs as the mode 504.0\n",
      "Column 58 has been encoded with NaNs as the mode 2.0\n",
      "Column 59 has been encoded with NaNs as the mode 2.0\n",
      "Column 60 has been encoded with NaNs as the mode 2.0\n",
      "Column 61 has been encoded with NaNs as the mode 2.0\n",
      "Column 62 has been encoded with NaNs as the mode 2.0\n",
      "Column 63 has been encoded with NaNs as the mode 2.0\n",
      "Column 64 has been encoded with NaNs as the mode 2.0\n",
      "Column 65 has been encoded with NaNs as the mode 2.0\n",
      "Column 66 has been encoded with NaNs as the mode 3.0\n",
      "Column 67 has been encoded with NaNs as the mode 7.0\n",
      "Column 68 has been encoded with NaNs as the mode 3.0\n",
      "Column 69 has been encoded with NaNs as the mode 888.0\n",
      "Column 70 has been encoded with NaNs as the mode 1.0\n",
      "Column 71 has been encoded with NaNs as the mode 88.0\n",
      "Column 72 has been encoded with NaNs as the mode 2.0\n",
      "Column 73 has been encoded with NaNs as the mode 555.0\n",
      "Column 74 has been encoded with NaNs as the mode 101.0\n",
      "Column 75 has been encoded with NaNs as the mode 555.0\n",
      "Column 76 has been encoded with NaNs as the mode 101.0\n",
      "Column 77 has been encoded with NaNs as the mode 555.0\n",
      "Column 78 has been encoded with NaNs as the mode 101.0\n",
      "Column 79 has been encoded with NaNs as the mode 1.0\n",
      "Column 80 has been encoded with NaNs as the mode 64.0\n",
      "Column 81 has been encoded with NaNs as the mode 103.0\n",
      "Column 82 has been encoded with NaNs as the mode 30.0\n",
      "Column 83 has been encoded with NaNs as the mode 88.0\n",
      "Column 84 has been encoded with NaNs as the mode 102.0\n",
      "Column 85 has been encoded with NaNs as the mode 30.0\n",
      "Column 86 has been encoded with NaNs as the mode 888.0\n",
      "Column 87 has been encoded with NaNs as the mode 2.0\n",
      "Column 88 has been encoded with NaNs as the mode 2.0\n",
      "Column 89 has been encoded with NaNs as the mode 3.0\n",
      "Column 90 has been encoded with NaNs as the mode 5.0\n",
      "Column 91 has been encoded with NaNs as the mode 1.0\n",
      "Column 92 has been encoded with NaNs as the mode 2.0\n",
      "Column 93 has been encoded with NaNs as the mode 102014.0\n",
      "Column 94 has been encoded with NaNs as the mode 1.0\n",
      "Column 95 has been encoded with NaNs as the mode 2.0\n",
      "Column 96 has been encoded with NaNs as the mode 2.0\n",
      "Column 97 has been encoded with NaNs as the mode 777777.0\n",
      "Column 98 has been encoded with NaNs as the mode 1.0\n",
      "Column 99 has been encoded with NaNs as the mode 2.0\n",
      "Column 100 has been encoded with NaNs as the mode 2.0\n",
      "Column 101 has been encoded with NaNs as the mode 1.0\n",
      "Column 102 has been encoded with NaNs as the mode 4.0\n",
      "Column 104 has been encoded with NaNs as the mode 1.0\n",
      "Column 105 has been encoded with NaNs as the mode 1.0\n",
      "Column 110 has been encoded with NaNs as the mode 9.0\n",
      "Column 118 has been encoded with NaNs as the mode 1.0\n",
      "Column 122 has been encoded with NaNs as the mode 2.0\n",
      "Column 129 has been encoded with NaNs as the mode 1.0\n",
      "Column 134 has been encoded with NaNs as the mode 64.0\n",
      "Column 138 has been encoded with NaNs as the mode 3.0\n",
      "Column 173 has been encoded with NaNs as the mode 1.0\n",
      "Column 174 has been encoded with NaNs as the mode 0.0\n",
      "Column 175 has been encoded with NaNs as the mode 30.0\n",
      "Column 176 has been encoded with NaNs as the mode 30.0\n",
      "Column 179 has been encoded with NaNs as the mode 180.0\n",
      "Column 180 has been encoded with NaNs as the mode 0.0\n",
      "Column 183 has been encoded with NaNs as the mode 0.0\n",
      "Column 184 has been encoded with NaNs as the mode 0.0\n",
      "Column 185 has been encoded with NaNs as the mode 180.0\n",
      "Column 186 has been encoded with NaNs as the mode 0.0\n",
      "Column 187 has been encoded with NaNs as the mode 0.0\n",
      "Column 188 has been encoded with NaNs as the mode 0.0\n",
      "Column 197 has been encoded with NaNs as the mode 3.0\n",
      "Column 198 has been encoded with NaNs as the mode 3.0\n",
      "Column 199 has been encoded with NaNs as the mode 4.0\n",
      "Column 202 has been encoded with NaNs as the mode 1.0\n",
      "Column 203 has been encoded with NaNs as the mode 1.0\n",
      "Column 204 has been encoded with NaNs as the mode 2.0\n",
      "Number of integer columns encoded: 105\n",
      "Column 107 has been encoded with NaNs as the binned mode 8.956952611387733\n",
      "Column 112 has been encoded with NaNs as the binned mode 0.7649543617619013\n",
      "Column 135 has been encoded with NaNs as the binned mode 1.6375\n",
      "Column 136 has been encoded with NaNs as the binned mode 66.76304999999999\n",
      "Column 137 has been encoded with NaNs as the binned mode 26.14895\n",
      "Column 150 has been encoded with NaNs as the binned mode 0.495\n",
      "Column 151 has been encoded with NaNs as the binned mode 0.495\n",
      "Column 152 has been encoded with NaNs as the binned mode 0.495\n",
      "Column 153 has been encoded with NaNs as the binned mode 0.495\n",
      "Column 154 has been encoded with NaNs as the binned mode 0.495\n",
      "Column 155 has been encoded with NaNs as the binned mode 0.495\n",
      "Column 160 has been encoded with NaNs as the binned mode 0.75\n",
      "Column 161 has been encoded with NaNs as the binned mode 0.99645\n",
      "Column 169 has been encoded with NaNs as the binned mode 3.52\n",
      "Column 170 has been encoded with NaNs as the binned mode 0.064\n",
      "Column 177 has been encoded with NaNs as the binned mode 2.7021749999999995\n",
      "Column 178 has been encoded with NaNs as the binned mode 0.726835\n",
      "Column 181 has been encoded with NaNs as the binned mode 0.495\n",
      "Number of non integer columns encoded: 18\n",
      "Column 9 has been encoded with NaNs as the mode 1.0\n",
      "Column 10 has been encoded with NaNs as the mode 1.0\n",
      "Column 11 has been encoded with NaNs as the mode 1.0\n",
      "Column 12 has been encoded with NaNs as the mode 2.0\n",
      "Column 13 has been encoded with NaNs as the mode 2.0\n",
      "Column 14 has been encoded with NaNs as the mode 1.0\n",
      "Column 15 has been encoded with NaNs as the mode 1.0\n",
      "Column 16 has been encoded with NaNs as the mode 1.0\n",
      "Column 17 has been encoded with NaNs as the mode 1.0\n",
      "Column 18 has been encoded with NaNs as the mode 2.0\n",
      "Column 19 has been encoded with NaNs as the mode 1.0\n",
      "Column 20 has been encoded with NaNs as the mode 1.0\n",
      "Column 21 has been encoded with NaNs as the mode 2.0\n",
      "Column 22 has been encoded with NaNs as the mode 2.0\n",
      "Column 26 has been encoded with NaNs as the mode 88.0\n",
      "Column 32 has been encoded with NaNs as the mode 1.0\n",
      "Column 34 has been encoded with NaNs as the mode 1.0\n",
      "Column 35 has been encoded with NaNs as the mode 2.0\n",
      "Column 44 has been encoded with NaNs as the mode 3.0\n",
      "Column 49 has been encoded with NaNs as the mode 2.0\n",
      "Column 50 has been encoded with NaNs as the mode 1.0\n",
      "Column 51 has been encoded with NaNs as the mode 2.0\n",
      "Column 53 has been encoded with NaNs as the mode 88.0\n",
      "Column 54 has been encoded with NaNs as the mode 8.0\n",
      "Column 55 has been encoded with NaNs as the mode 1.0\n",
      "Column 56 has been encoded with NaNs as the mode 200.0\n",
      "Column 57 has been encoded with NaNs as the mode 506.0\n",
      "Column 58 has been encoded with NaNs as the mode 2.0\n",
      "Column 59 has been encoded with NaNs as the mode 2.0\n",
      "Column 60 has been encoded with NaNs as the mode 2.0\n",
      "Column 61 has been encoded with NaNs as the mode 2.0\n",
      "Column 62 has been encoded with NaNs as the mode 2.0\n",
      "Column 63 has been encoded with NaNs as the mode 2.0\n",
      "Column 64 has been encoded with NaNs as the mode 2.0\n",
      "Column 65 has been encoded with NaNs as the mode 2.0\n",
      "Column 66 has been encoded with NaNs as the mode 3.0\n",
      "Column 67 has been encoded with NaNs as the mode 7.0\n",
      "Column 68 has been encoded with NaNs as the mode 3.0\n",
      "Column 69 has been encoded with NaNs as the mode 888.0\n",
      "Column 70 has been encoded with NaNs as the mode 1.0\n",
      "Column 71 has been encoded with NaNs as the mode 88.0\n",
      "Column 72 has been encoded with NaNs as the mode 1.0\n",
      "Column 73 has been encoded with NaNs as the mode 555.0\n",
      "Column 74 has been encoded with NaNs as the mode 101.0\n",
      "Column 75 has been encoded with NaNs as the mode 555.0\n",
      "Column 76 has been encoded with NaNs as the mode 101.0\n",
      "Column 77 has been encoded with NaNs as the mode 555.0\n",
      "Column 78 has been encoded with NaNs as the mode 101.0\n",
      "Column 79 has been encoded with NaNs as the mode 1.0\n",
      "Column 80 has been encoded with NaNs as the mode 64.0\n",
      "Column 81 has been encoded with NaNs as the mode 103.0\n",
      "Column 82 has been encoded with NaNs as the mode 30.0\n",
      "Column 83 has been encoded with NaNs as the mode 88.0\n",
      "Column 84 has been encoded with NaNs as the mode 102.0\n",
      "Column 85 has been encoded with NaNs as the mode 100.0\n",
      "Column 86 has been encoded with NaNs as the mode 888.0\n",
      "Column 87 has been encoded with NaNs as the mode 2.0\n",
      "Column 88 has been encoded with NaNs as the mode 2.0\n",
      "Column 89 has been encoded with NaNs as the mode 3.0\n",
      "Column 90 has been encoded with NaNs as the mode 5.0\n",
      "Column 91 has been encoded with NaNs as the mode 1.0\n",
      "Column 92 has been encoded with NaNs as the mode 2.0\n",
      "Column 93 has been encoded with NaNs as the mode 102014.0\n",
      "Column 94 has been encoded with NaNs as the mode 1.0\n",
      "Column 95 has been encoded with NaNs as the mode 2.0\n",
      "Column 96 has been encoded with NaNs as the mode 2.0\n",
      "Column 97 has been encoded with NaNs as the mode 777777.0\n",
      "Column 98 has been encoded with NaNs as the mode 1.0\n",
      "Column 99 has been encoded with NaNs as the mode 2.0\n",
      "Column 100 has been encoded with NaNs as the mode 2.0\n",
      "Column 101 has been encoded with NaNs as the mode 1.0\n",
      "Column 102 has been encoded with NaNs as the mode 4.0\n",
      "Column 104 has been encoded with NaNs as the mode 1.0\n",
      "Column 105 has been encoded with NaNs as the mode 1.0\n",
      "Column 110 has been encoded with NaNs as the mode 9.0\n",
      "Column 118 has been encoded with NaNs as the mode 1.0\n",
      "Column 122 has been encoded with NaNs as the mode 2.0\n",
      "Column 129 has been encoded with NaNs as the mode 1.0\n",
      "Column 134 has been encoded with NaNs as the mode 66.0\n",
      "Column 138 has been encoded with NaNs as the mode 3.0\n",
      "Column 173 has been encoded with NaNs as the mode 1.0\n",
      "Column 174 has been encoded with NaNs as the mode 0.0\n",
      "Column 175 has been encoded with NaNs as the mode 30.0\n",
      "Column 176 has been encoded with NaNs as the mode 60.0\n",
      "Column 179 has been encoded with NaNs as the mode 180.0\n",
      "Column 180 has been encoded with NaNs as the mode 0.0\n",
      "Column 183 has been encoded with NaNs as the mode 0.0\n",
      "Column 184 has been encoded with NaNs as the mode 0.0\n",
      "Column 185 has been encoded with NaNs as the mode 180.0\n",
      "Column 186 has been encoded with NaNs as the mode 0.0\n",
      "Column 187 has been encoded with NaNs as the mode 0.0\n",
      "Column 188 has been encoded with NaNs as the mode 0.0\n",
      "Column 197 has been encoded with NaNs as the mode 3.0\n",
      "Column 198 has been encoded with NaNs as the mode 3.0\n",
      "Column 199 has been encoded with NaNs as the mode 4.0\n",
      "Column 202 has been encoded with NaNs as the mode 1.0\n",
      "Column 203 has been encoded with NaNs as the mode 1.0\n",
      "Column 204 has been encoded with NaNs as the mode 2.0\n",
      "Number of integer columns encoded: 98\n",
      "Column 107 has been encoded with NaNs as the binned mode 8.956952611387733\n",
      "Column 112 has been encoded with NaNs as the binned mode 0.68925311554367\n",
      "Column 135 has been encoded with NaNs as the binned mode 1.6835\n",
      "Column 136 has been encoded with NaNs as the binned mode 69.16865000000001\n",
      "Column 137 has been encoded with NaNs as the binned mode 26.845750000000002\n",
      "Column 150 has been encoded with NaNs as the binned mode 0.15\n",
      "Column 151 has been encoded with NaNs as the binned mode 0.495\n",
      "Column 152 has been encoded with NaNs as the binned mode 0.175\n",
      "Column 153 has been encoded with NaNs as the binned mode 0.15\n",
      "Column 154 has been encoded with NaNs as the binned mode 0.125\n",
      "Column 155 has been encoded with NaNs as the binned mode 0.495\n",
      "Column 160 has been encoded with NaNs as the binned mode 0.5\n",
      "Column 161 has been encoded with NaNs as the binned mode 1.5115500000000002\n",
      "Column 169 has been encoded with NaNs as the binned mode 3.52\n",
      "Column 170 has been encoded with NaNs as the binned mode 0.064\n",
      "Column 177 has been encoded with NaNs as the binned mode 2.7021749999999995\n",
      "Column 178 has been encoded with NaNs as the binned mode 0.726835\n",
      "Column 181 has been encoded with NaNs as the binned mode 0.495\n",
      "Number of non integer columns encoded: 18\n"
     ]
    }
   ],
   "source": [
    "x_balanced, y_balanced, deleted_ids = balance_classes(x_train, y_train, 1)\n",
    "\n",
    "x_train_cleaned, deleted_indices = remove_nan_features(x_train, 0.8)\n",
    "adapted_x_test = np.delete(x_test, deleted_indices, axis=1)\n",
    "\n",
    "\n",
    "integer_columns, non_integer_columns = identify_integer_columns(x_train_cleaned)\n",
    "assert len(integer_columns) + len(non_integer_columns) == x_train_cleaned.shape[1]\n",
    "\n",
    "x_train_cleaned_without_nans = encode_nan_integer_columns(x_train_cleaned, replacement_value='mode')\n",
    "x_train_cleaned_without_nans = encode_nan_continuous_columns(x_train_cleaned_without_nans, replacement_value='mode')\n",
    "assert np.isnan(x_train_cleaned_without_nans).sum() == 0\n",
    "assert x_train_cleaned.shape == x_train_cleaned_without_nans.shape\n",
    "adapted_x_test_without_nans = encode_nan_integer_columns(adapted_x_test, replacement_value='mode')\n",
    "adapted_x_test_without_nans = encode_nan_continuous_columns(adapted_x_test_without_nans, replacement_value='mode')\n",
    "assert np.isnan(adapted_x_test_without_nans).sum() == 0\n",
    "assert adapted_x_test.shape == adapted_x_test_without_nans.shape\n",
    "\n",
    "categorical_threshold = 5\n",
    "unique_value_counts = np.array([len(np.unique(x_train_cleaned[:, col])) for col in integer_columns])\n",
    "indexes_categorical_features = [integer_columns[i] for i, count in enumerate(unique_value_counts) if count <= categorical_threshold]\n",
    "indexes_non_categorical_features = [integer_columns[i] for i in range(len(unique_value_counts)) if integer_columns[i] not in indexes_categorical_features]\n",
    "assert len(indexes_categorical_features) + len(indexes_non_categorical_features) == len(unique_value_counts)\n",
    "assert unique_value_counts.size == len(integer_columns)\n",
    "indexes_non_categorical_features.extend(non_integer_columns)\n",
    "\n",
    "x_standardized = standardize_columns(x_train_cleaned_without_nans, indexes_non_categorical_features)\n",
    "x_test_standardized = standardize_columns(adapted_x_test_without_nans, indexes_non_categorical_features)\n",
    "\n",
    "encoded_x_train, encoded_x_test = consistent_binary_encode(x_standardized, x_test_standardized, indexes_categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NaNs in x_train:\", np.isnan(x_train).any())\n",
    "print(\"Infs in x_train:\", np.isinf(x_train).any())\n",
    "print(\"NaNs in y_train:\", np.isnan(y_train).any())\n",
    "print(\"Infs in y_train:\", np.isinf(y_train).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Models and Hyperparameter Grids\n",
    "# Dictionary of model functions\n",
    "models = {\n",
    "    # \"mean_squared_error_gd\": mean_squared_error_gd,\n",
    "    # \"mean_squared_error_sgd\": mean_squared_error_sgd,\n",
    "    # \"least_squares\": least_squares,\n",
    "    # \"ridge_regression\": ridge_regression,\n",
    "    \"logistic_regression\": logistic_regression,\n",
    "    # \"reg_logistic_regression\": reg_logistic_regression\n",
    "}\n",
    "\n",
    "# # Define hyperparameter grids for each model\n",
    "param_grid = {\n",
    "    \"mean_squared_error_gd\": {\"max_iters\": [15], \"gamma\": np.linspace(0.0001, 0.00001, 5).tolist()},\n",
    "    \"mean_squared_error_sgd\": {\"max_iters\": [15], \"gamma\": np.linspace(0.0001, 0.00001, 5).tolist()},\n",
    "    \"least_squares\": {},  # No hyperparameters for least squares\n",
    "    \"ridge_regression\": {\"lambda_\": [0.2, 0.1, 0.01, 0.001, 0.0001]},\n",
    "    \"logistic_regression\": {\"max_iters\": [15], \"gamma\": np.linspace(0.1, 0.00001, 100).tolist()},\n",
    "    \"reg_logistic_regression\": {\"max_iters\": [15], \"gamma\": np.linspace(0.0001, 0.00001, 5).tolist(), \"lambda_\": [0.2, 0.1, 0.01, 0.001, 0.0001]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning logistic_regression...\n",
      "Current iteration=0, loss=-4.152944279674938\n",
      "Current iteration=0, loss=-4.154141734991706\n",
      "Current iteration=0, loss=-4.155204516566228\n",
      "Current iteration=0, loss=-4.149760050983611\n",
      "Current iteration=0, loss=-4.148600283976261\n",
      "Params: {'max_iters': 15, 'gamma': 0.1}, Cross-validated loss: 1147.9360756294175\n",
      "Current iteration=0, loss=-4.112778308925582\n",
      "Current iteration=0, loss=-4.11251917517242\n",
      "Current iteration=0, loss=-4.107548286674249\n",
      "Current iteration=0, loss=-4.1046388653197186\n",
      "Current iteration=0, loss=-4.1111413660941745\n",
      "Params: {'max_iters': 15, 'gamma': 0.09899000000000001}, Cross-validated loss: 1124.5408970802087\n",
      "Current iteration=0, loss=-4.066160219317966\n",
      "Current iteration=0, loss=-4.069042846999393\n",
      "Current iteration=0, loss=-4.06306427564047\n",
      "Current iteration=0, loss=-4.066968272201689\n",
      "Current iteration=0, loss=-4.071294086065825\n",
      "Params: {'max_iters': 15, 'gamma': 0.09798000000000001}, Cross-validated loss: 1101.378797168466\n",
      "Current iteration=0, loss=-4.028773003807171\n",
      "Current iteration=0, loss=-4.025241609626816\n",
      "Current iteration=0, loss=-4.021548292447452\n",
      "Current iteration=0, loss=-4.024118395441077\n",
      "Current iteration=0, loss=-4.024645357329901\n",
      "Params: {'max_iters': 15, 'gamma': 0.09697}, Cross-validated loss: 1078.4638794666134\n",
      "Current iteration=0, loss=-3.990245276320305\n",
      "Current iteration=0, loss=-3.982841860007817\n",
      "Current iteration=0, loss=-3.978801137842205\n",
      "Current iteration=0, loss=-3.9820345964965354\n",
      "Current iteration=0, loss=-3.978079806742522\n",
      "Params: {'max_iters': 15, 'gamma': 0.09596}, Cross-validated loss: 1055.7999491324579\n",
      "Current iteration=0, loss=-3.9483530790677768\n",
      "Current iteration=0, loss=-3.932364311638874\n",
      "Current iteration=0, loss=-3.934534450538985\n",
      "Current iteration=0, loss=-3.9451354776462937\n",
      "Current iteration=0, loss=-3.9391947677763555\n",
      "Params: {'max_iters': 15, 'gamma': 0.09495}, Cross-validated loss: 1033.377422474407\n",
      "Current iteration=0, loss=-3.8946617833995756\n",
      "Current iteration=0, loss=-3.897745252026451\n",
      "Current iteration=0, loss=-3.903577674479462\n",
      "Current iteration=0, loss=-3.894095867589626\n",
      "Current iteration=0, loss=-3.8969611688183354\n",
      "Params: {'max_iters': 15, 'gamma': 0.09394000000000001}, Cross-validated loss: 1011.1929035222449\n",
      "Current iteration=0, loss=-3.8571704160213067\n",
      "Current iteration=0, loss=-3.8601551654399526\n",
      "Current iteration=0, loss=-3.8468593831086695\n",
      "Current iteration=0, loss=-3.8521551615529686\n",
      "Current iteration=0, loss=-3.858047300369482\n",
      "Params: {'max_iters': 15, 'gamma': 0.09293000000000001}, Cross-validated loss: 989.2562557976713\n",
      "Current iteration=0, loss=-3.8077897426134784\n",
      "Current iteration=0, loss=-3.810542799043827\n",
      "Current iteration=0, loss=-3.816039813984449\n",
      "Current iteration=0, loss=-3.8196902056681585\n",
      "Current iteration=0, loss=-3.8075559125437586\n",
      "Params: {'max_iters': 15, 'gamma': 0.09192}, Cross-validated loss: 967.5564847564167\n",
      "Current iteration=0, loss=-3.7704169607416347\n",
      "Current iteration=0, loss=-3.771887613930331\n",
      "Current iteration=0, loss=-3.7741793286053342\n",
      "Current iteration=0, loss=-3.7610778310505064\n",
      "Current iteration=0, loss=-3.77113910093175\n",
      "Params: {'max_iters': 15, 'gamma': 0.09091}, Cross-validated loss: 946.104098484727\n",
      "Current iteration=0, loss=-3.7240767546450226\n",
      "Current iteration=0, loss=-3.732542220615246\n",
      "Current iteration=0, loss=-3.7265674794015125\n",
      "Current iteration=0, loss=-3.7246527538128475\n",
      "Current iteration=0, loss=-3.7278178024733406\n",
      "Params: {'max_iters': 15, 'gamma': 0.08990000000000001}, Cross-validated loss: 924.8937714006688\n",
      "Current iteration=0, loss=-3.68761236693716\n",
      "Current iteration=0, loss=-3.6834685163644445\n",
      "Current iteration=0, loss=-3.6860935575401372\n",
      "Current iteration=0, loss=-3.6806615155370306\n",
      "Current iteration=0, loss=-3.6846324232942065\n",
      "Params: {'max_iters': 15, 'gamma': 0.08889000000000001}, Cross-validated loss: 903.9252852356564\n",
      "Current iteration=0, loss=-3.643617181672569\n",
      "Current iteration=0, loss=-3.637672733381745\n",
      "Current iteration=0, loss=-3.645084466154793\n",
      "Current iteration=0, loss=-3.640076799049435\n",
      "Current iteration=0, loss=-3.6426796247484847\n",
      "Params: {'max_iters': 15, 'gamma': 0.08788}, Cross-validated loss: 883.2013165620035\n",
      "Current iteration=0, loss=-3.5976045837695914\n",
      "Current iteration=0, loss=-3.6045042651345764\n",
      "Current iteration=0, loss=-3.5957528726990335\n",
      "Current iteration=0, loss=-3.594835099604536\n",
      "Current iteration=0, loss=-3.602943792654916\n",
      "Params: {'max_iters': 15, 'gamma': 0.08687}, Cross-validated loss: 862.7216932971166\n",
      "Current iteration=0, loss=-3.556238975758969\n",
      "Current iteration=0, loss=-3.5565948466207487\n",
      "Current iteration=0, loss=-3.5601343582147\n",
      "Current iteration=0, loss=-3.5562205584334556\n",
      "Current iteration=0, loss=-3.5527756969270583\n",
      "Params: {'max_iters': 15, 'gamma': 0.08586}, Cross-validated loss: 842.4843418304592\n",
      "Current iteration=0, loss=-3.5147964733176473\n",
      "Current iteration=0, loss=-3.509226926201913\n",
      "Current iteration=0, loss=-3.512809219596859\n",
      "Current iteration=0, loss=-3.509938655328769\n",
      "Current iteration=0, loss=-3.5213620829216037\n",
      "Params: {'max_iters': 15, 'gamma': 0.08485000000000001}, Cross-validated loss: 822.490032801324\n",
      "Current iteration=0, loss=-3.466711816784971\n",
      "Current iteration=0, loss=-3.466703628521546\n",
      "Current iteration=0, loss=-3.473447509734777\n",
      "Current iteration=0, loss=-3.472680326222432\n",
      "Current iteration=0, loss=-3.474578680176156\n",
      "Params: {'max_iters': 15, 'gamma': 0.08384}, Cross-validated loss: 802.7367270404328\n",
      "Current iteration=0, loss=-3.4285530247775236\n",
      "Current iteration=0, loss=-3.426128353832929\n",
      "Current iteration=0, loss=-3.429269459855726\n",
      "Current iteration=0, loss=-3.42540405868607\n",
      "Current iteration=0, loss=-3.43054538017447\n",
      "Params: {'max_iters': 15, 'gamma': 0.08283}, Cross-validated loss: 783.2294215866929\n",
      "Current iteration=0, loss=-3.3885421260835695\n",
      "Current iteration=0, loss=-3.384116139173654\n",
      "Current iteration=0, loss=-3.3868815392719562\n",
      "Current iteration=0, loss=-3.3826508779215625\n",
      "Current iteration=0, loss=-3.3833068316236017\n",
      "Params: {'max_iters': 15, 'gamma': 0.08182}, Cross-validated loss: 763.9629283169199\n",
      "Current iteration=0, loss=-3.337824144215861\n",
      "Current iteration=0, loss=-3.346359452429827\n",
      "Current iteration=0, loss=-3.342730488401974\n",
      "Current iteration=0, loss=-3.3379143357910106\n",
      "Current iteration=0, loss=-3.3460545279012694\n",
      "Params: {'max_iters': 15, 'gamma': 0.08081}, Cross-validated loss: 744.9391205741022\n",
      "Current iteration=0, loss=-3.302878142528359\n",
      "Current iteration=0, loss=-3.2987553130128906\n",
      "Current iteration=0, loss=-3.2942630354866567\n",
      "Current iteration=0, loss=-3.3040587719601886\n",
      "Current iteration=0, loss=-3.296089348079644\n",
      "Params: {'max_iters': 15, 'gamma': 0.07980000000000001}, Cross-validated loss: 726.1593827689042\n",
      "Current iteration=0, loss=-3.2542223586227235\n",
      "Current iteration=0, loss=-3.2586185074310463\n",
      "Current iteration=0, loss=-3.252938801967081\n",
      "Current iteration=0, loss=-3.2563334652901252\n",
      "Current iteration=0, loss=-3.2588582942747646\n",
      "Params: {'max_iters': 15, 'gamma': 0.07879}, Cross-validated loss: 707.6236957241246\n",
      "Current iteration=0, loss=-3.2127721232953994\n",
      "Current iteration=0, loss=-3.208007332430943\n",
      "Current iteration=0, loss=-3.2182037065277758\n",
      "Current iteration=0, loss=-3.2154321119723126\n",
      "Current iteration=0, loss=-3.211246449154285\n",
      "Params: {'max_iters': 15, 'gamma': 0.07778}, Cross-validated loss: 689.3307099295741\n",
      "Current iteration=0, loss=-3.173952954351752\n",
      "Current iteration=0, loss=-3.169868518851043\n",
      "Current iteration=0, loss=-3.1669782294918756\n",
      "Current iteration=0, loss=-3.1703556803189485\n",
      "Current iteration=0, loss=-3.168934032735294\n",
      "Params: {'max_iters': 15, 'gamma': 0.07677}, Cross-validated loss: 671.2811488717741\n",
      "Current iteration=0, loss=-3.121722827431767\n",
      "Current iteration=0, loss=-3.127088759129978\n",
      "Current iteration=0, loss=-3.1296651315703565\n",
      "Current iteration=0, loss=-3.131194087178769\n",
      "Current iteration=0, loss=-3.1246049746435567\n",
      "Params: {'max_iters': 15, 'gamma': 0.07576000000000001}, Cross-validated loss: 653.4694271580471\n",
      "Current iteration=0, loss=-3.0884807844345668\n",
      "Current iteration=0, loss=-3.082672205567056\n",
      "Current iteration=0, loss=-3.082889194530584\n",
      "Current iteration=0, loss=-3.08528644824101\n",
      "Current iteration=0, loss=-3.0788350616007207\n",
      "Params: {'max_iters': 15, 'gamma': 0.07475000000000001}, Cross-validated loss: 635.9062927682803\n",
      "Current iteration=0, loss=-3.0417163756917684\n",
      "Current iteration=0, loss=-3.0385462708755386\n",
      "Current iteration=0, loss=-3.0359195340449108\n",
      "Current iteration=0, loss=-3.0435229138259188\n",
      "Current iteration=0, loss=-3.0420646000275857\n",
      "Params: {'max_iters': 15, 'gamma': 0.07374}, Cross-validated loss: 618.5823874386049\n",
      "Current iteration=0, loss=-2.9984753814300915\n",
      "Current iteration=0, loss=-2.993484488778245\n",
      "Current iteration=0, loss=-2.9959904412706284\n",
      "Current iteration=0, loss=-2.995854150777038\n",
      "Current iteration=0, loss=-3.001258128812862\n",
      "Params: {'max_iters': 15, 'gamma': 0.07273}, Cross-validated loss: 601.5034512250236\n",
      "Current iteration=0, loss=-2.9476690750383487\n",
      "Current iteration=0, loss=-2.9552864824199907\n",
      "Current iteration=0, loss=-2.95313686194823\n",
      "Current iteration=0, loss=-2.953955850178821\n",
      "Current iteration=0, loss=-2.957991105112643\n",
      "Params: {'max_iters': 15, 'gamma': 0.07172}, Cross-validated loss: 584.6668636285108\n",
      "Current iteration=0, loss=-2.9079571734324694\n",
      "Current iteration=0, loss=-2.9055272023092633\n",
      "Current iteration=0, loss=-2.9079732999278867\n",
      "Current iteration=0, loss=-2.9173165980282003\n",
      "Current iteration=0, loss=-2.911897603566997\n",
      "Params: {'max_iters': 15, 'gamma': 0.07071000000000001}, Cross-validated loss: 568.0752364892653\n",
      "Current iteration=0, loss=-2.8706020299115047\n",
      "Current iteration=0, loss=-2.861334704868301\n",
      "Current iteration=0, loss=-2.8652019674818487\n",
      "Current iteration=0, loss=-2.866003471691701\n",
      "Current iteration=0, loss=-2.86983204513551\n",
      "Params: {'max_iters': 15, 'gamma': 0.06970000000000001}, Cross-validated loss: 551.7202223747161\n",
      "Current iteration=0, loss=-2.824460657265598\n",
      "Current iteration=0, loss=-2.8222437134989113\n",
      "Current iteration=0, loss=-2.822256105191929\n",
      "Current iteration=0, loss=-2.81999014886243\n",
      "Current iteration=0, loss=-2.825937782639715\n",
      "Params: {'max_iters': 15, 'gamma': 0.06869}, Cross-validated loss: 535.6119107349342\n",
      "Current iteration=0, loss=-2.7771040504331137\n",
      "Current iteration=0, loss=-2.777930259894113\n",
      "Current iteration=0, loss=-2.778096622239996\n",
      "Current iteration=0, loss=-2.7819850875064276\n",
      "Current iteration=0, loss=-2.781310637978523\n",
      "Params: {'max_iters': 15, 'gamma': 0.06768}, Cross-validated loss: 519.7449636089317\n",
      "Current iteration=0, loss=-2.73770816107931\n",
      "Current iteration=0, loss=-2.743744135484509\n",
      "Current iteration=0, loss=-2.7295162157960546\n",
      "Current iteration=0, loss=-2.7341739828957063\n",
      "Current iteration=0, loss=-2.732426997833565\n",
      "Params: {'max_iters': 15, 'gamma': 0.06667000000000001}, Cross-validated loss: 504.12037342455505\n",
      "Current iteration=0, loss=-2.6920847849614162\n",
      "Current iteration=0, loss=-2.6925447454923606\n",
      "Current iteration=0, loss=-2.6891190799652995\n",
      "Current iteration=0, loss=-2.6925715380092474\n",
      "Current iteration=0, loss=-2.6919453963668496\n",
      "Params: {'max_iters': 15, 'gamma': 0.06566}, Cross-validated loss: 488.739312101377\n",
      "Current iteration=0, loss=-2.6475173396297924\n",
      "Current iteration=0, loss=-2.643536699793601\n",
      "Current iteration=0, loss=-2.6476815946496437\n",
      "Current iteration=0, loss=-2.6505396731301065\n",
      "Current iteration=0, loss=-2.6492632212388116\n",
      "Params: {'max_iters': 15, 'gamma': 0.06465000000000001}, Cross-validated loss: 473.5976582703931\n",
      "Current iteration=0, loss=-2.6037611744739206\n",
      "Current iteration=0, loss=-2.602997910040578\n",
      "Current iteration=0, loss=-2.604828407637994\n",
      "Current iteration=0, loss=-2.603729818156123\n",
      "Current iteration=0, loss=-2.6030274564549423\n",
      "Params: {'max_iters': 15, 'gamma': 0.06364}, Cross-validated loss: 458.6998893100823\n",
      "Current iteration=0, loss=-2.563233676785733\n",
      "Current iteration=0, loss=-2.559847195802939\n",
      "Current iteration=0, loss=-2.5588339582244317\n",
      "Current iteration=0, loss=-2.5568949257445626\n",
      "Current iteration=0, loss=-2.558842706654682\n",
      "Params: {'max_iters': 15, 'gamma': 0.06263}, Cross-validated loss: 444.0461603493562\n",
      "Current iteration=0, loss=-2.5133196066982966\n",
      "Current iteration=0, loss=-2.5159959442368076\n",
      "Current iteration=0, loss=-2.5172632391077\n",
      "Current iteration=0, loss=-2.518223962123085\n",
      "Current iteration=0, loss=-2.511676061546854\n",
      "Params: {'max_iters': 15, 'gamma': 0.06162}, Cross-validated loss: 429.62983366615646\n",
      "Current iteration=0, loss=-2.474095675000493\n",
      "Current iteration=0, loss=-2.4707963323606856\n",
      "Current iteration=0, loss=-2.4719685474166417\n",
      "Current iteration=0, loss=-2.469664835301789\n",
      "Current iteration=0, loss=-2.4682288829246843\n",
      "Params: {'max_iters': 15, 'gamma': 0.060610000000000004}, Cross-validated loss: 415.4581621785874\n",
      "Current iteration=0, loss=-2.4240308165641933\n",
      "Current iteration=0, loss=-2.4288977446603264\n",
      "Current iteration=0, loss=-2.4258060094324083\n",
      "Current iteration=0, loss=-2.426087916087717\n",
      "Current iteration=0, loss=-2.4276593101663155\n",
      "Params: {'max_iters': 15, 'gamma': 0.0596}, Cross-validated loss: 401.5265142574806\n",
      "Current iteration=0, loss=-2.382908400329413\n",
      "Current iteration=0, loss=-2.380970034900999\n",
      "Current iteration=0, loss=-2.381009331690737\n",
      "Current iteration=0, loss=-2.382024288471971\n",
      "Current iteration=0, loss=-2.3827127516286293\n",
      "Params: {'max_iters': 15, 'gamma': 0.05859}, Cross-validated loss: 387.83759156477396\n",
      "Current iteration=0, loss=-2.332060597455172\n",
      "Current iteration=0, loss=-2.3369468180354716\n",
      "Current iteration=0, loss=-2.33885244442335\n",
      "Current iteration=0, loss=-2.338163367339387\n",
      "Current iteration=0, loss=-2.340145249528898\n",
      "Params: {'max_iters': 15, 'gamma': 0.057580000000000006}, Cross-validated loss: 374.3900106568341\n",
      "Current iteration=0, loss=-2.2911410202656683\n",
      "Current iteration=0, loss=-2.2955989378807837\n",
      "Current iteration=0, loss=-2.293985712825806\n",
      "Current iteration=0, loss=-2.292227283076133\n",
      "Current iteration=0, loss=-2.2891112745055118\n",
      "Params: {'max_iters': 15, 'gamma': 0.05657}, Cross-validated loss: 361.1835722738864\n",
      "Current iteration=0, loss=-2.2506585185447614\n",
      "Current iteration=0, loss=-2.245639864813428\n",
      "Current iteration=0, loss=-2.2486661356657764\n",
      "Current iteration=0, loss=-2.2439049182977504\n",
      "Current iteration=0, loss=-2.2484456580309304\n",
      "Params: {'max_iters': 15, 'gamma': 0.055560000000000005}, Cross-validated loss: 348.21612994358316\n",
      "Current iteration=0, loss=-2.204080048824738\n",
      "Current iteration=0, loss=-2.2035395548110985\n",
      "Current iteration=0, loss=-2.2025149679749125\n",
      "Current iteration=0, loss=-2.1995101368485663\n",
      "Current iteration=0, loss=-2.2022118513654085\n",
      "Params: {'max_iters': 15, 'gamma': 0.05455}, Cross-validated loss: 335.49187386740243\n",
      "Current iteration=0, loss=-2.155466981937771\n",
      "Current iteration=0, loss=-2.1581379332660906\n",
      "Current iteration=0, loss=-2.1592931637605743\n",
      "Current iteration=0, loss=-2.1549515038729337\n",
      "Current iteration=0, loss=-2.157837250497873\n",
      "Params: {'max_iters': 15, 'gamma': 0.053540000000000004}, Cross-validated loss: 323.00671847647266\n",
      "Current iteration=0, loss=-2.1141086836905676\n",
      "Current iteration=0, loss=-2.108535754529901\n",
      "Current iteration=0, loss=-2.1112309490600865\n",
      "Current iteration=0, loss=-2.114838456976684\n",
      "Current iteration=0, loss=-2.1100363292491013\n",
      "Params: {'max_iters': 15, 'gamma': 0.05253}, Cross-validated loss: 310.76318730358685\n",
      "Current iteration=0, loss=-2.064723342158119\n",
      "Current iteration=0, loss=-2.069230715881265\n",
      "Current iteration=0, loss=-2.0634928613334074\n",
      "Current iteration=0, loss=-2.067865899198151\n",
      "Current iteration=0, loss=-2.0657055364780192\n",
      "Params: {'max_iters': 15, 'gamma': 0.05152}, Cross-validated loss: 298.76050308935874\n",
      "Current iteration=0, loss=-2.0214848577846234\n",
      "Current iteration=0, loss=-2.020773471324769\n",
      "Current iteration=0, loss=-2.018546737316212\n",
      "Current iteration=0, loss=-2.0211758153280437\n",
      "Current iteration=0, loss=-2.0204840000795126\n",
      "Params: {'max_iters': 15, 'gamma': 0.050510000000000006}, Cross-validated loss: 286.9971278619123\n",
      "Current iteration=0, loss=-1.975576808819263\n",
      "Current iteration=0, loss=-1.974754385094956\n",
      "Current iteration=0, loss=-1.9773702011926864\n",
      "Current iteration=0, loss=-1.973055403908416\n",
      "Current iteration=0, loss=-1.9722986086326364\n",
      "Params: {'max_iters': 15, 'gamma': 0.0495}, Cross-validated loss: 275.4736320604581\n",
      "Current iteration=0, loss=-1.9284563359941258\n",
      "Current iteration=0, loss=-1.9307010680925611\n",
      "Current iteration=0, loss=-1.9293719077240394\n",
      "Current iteration=0, loss=-1.92601772913922\n",
      "Current iteration=0, loss=-1.9281912945910302\n",
      "Params: {'max_iters': 15, 'gamma': 0.048490000000000005}, Cross-validated loss: 264.1910847022916\n",
      "Current iteration=0, loss=-1.8810287649970936\n",
      "Current iteration=0, loss=-1.8832378352760797\n",
      "Current iteration=0, loss=-1.8831430649136442\n",
      "Current iteration=0, loss=-1.880159185432801\n",
      "Current iteration=0, loss=-1.8839230391659678\n",
      "Params: {'max_iters': 15, 'gamma': 0.04748}, Cross-validated loss: 253.14678067507504\n",
      "Current iteration=0, loss=-1.8366826272295163\n",
      "Current iteration=0, loss=-1.836639582301983\n",
      "Current iteration=0, loss=-1.8342569510861793\n",
      "Current iteration=0, loss=-1.83642626985763\n",
      "Current iteration=0, loss=-1.8352644063913384\n",
      "Params: {'max_iters': 15, 'gamma': 0.046470000000000004}, Cross-validated loss: 242.3414632230966\n",
      "Current iteration=0, loss=-1.7884065381684686\n",
      "Current iteration=0, loss=-1.7920744108793658\n",
      "Current iteration=0, loss=-1.7892126407623545\n",
      "Current iteration=0, loss=-1.7870153274353224\n",
      "Current iteration=0, loss=-1.7893170995319687\n",
      "Params: {'max_iters': 15, 'gamma': 0.04546}, Cross-validated loss: 231.77591251033763\n",
      "Current iteration=0, loss=-1.741411875634648\n",
      "Current iteration=0, loss=-1.7405195711669164\n",
      "Current iteration=0, loss=-1.7459585516026777\n",
      "Current iteration=0, loss=-1.744229975311618\n",
      "Current iteration=0, loss=-1.7395962111730494\n",
      "Params: {'max_iters': 15, 'gamma': 0.04445}, Cross-validated loss: 221.45014121119465\n",
      "Current iteration=0, loss=-1.6930028944063675\n",
      "Current iteration=0, loss=-1.696399635499389\n",
      "Current iteration=0, loss=-1.6933533991592387\n",
      "Current iteration=0, loss=-1.6966954350725454\n",
      "Current iteration=0, loss=-1.696849762945751\n",
      "Params: {'max_iters': 15, 'gamma': 0.043440000000000006}, Cross-validated loss: 211.36262751799177\n",
      "Current iteration=0, loss=-1.6489532193915775\n",
      "Current iteration=0, loss=-1.6486080058360342\n",
      "Current iteration=0, loss=-1.6480141921365505\n",
      "Current iteration=0, loss=-1.6479530421427524\n",
      "Current iteration=0, loss=-1.6462184551158834\n",
      "Params: {'max_iters': 15, 'gamma': 0.04243}, Cross-validated loss: 201.5113322903778\n",
      "Current iteration=0, loss=-1.5997609191330309\n",
      "Current iteration=0, loss=-1.600311419665735\n",
      "Current iteration=0, loss=-1.6014043042948345\n",
      "Current iteration=0, loss=-1.601097620567578\n",
      "Current iteration=0, loss=-1.5994045000446968\n",
      "Params: {'max_iters': 15, 'gamma': 0.041420000000000005}, Cross-validated loss: 191.90135013057974\n",
      "Current iteration=0, loss=-1.551199245391237\n",
      "Current iteration=0, loss=-1.553200784348852\n",
      "Current iteration=0, loss=-1.5535893342274567\n",
      "Current iteration=0, loss=-1.5541848478708455\n",
      "Current iteration=0, loss=-1.550797085785668\n",
      "Params: {'max_iters': 15, 'gamma': 0.04041}, Cross-validated loss: 182.52802557640385\n",
      "Current iteration=0, loss=-1.506502897966445\n",
      "Current iteration=0, loss=-1.5054499965868184\n",
      "Current iteration=0, loss=-1.5026887959108157\n",
      "Current iteration=0, loss=-1.5038578071529627\n",
      "Current iteration=0, loss=-1.5041778656642997\n",
      "Params: {'max_iters': 15, 'gamma': 0.039400000000000004}, Cross-validated loss: 173.39183039899277\n",
      "Current iteration=0, loss=-1.4561993013407892\n",
      "Current iteration=0, loss=-1.4564322448904248\n",
      "Current iteration=0, loss=-1.4570072264516514\n",
      "Current iteration=0, loss=-1.4557466700291184\n",
      "Current iteration=0, loss=-1.4556387730525053\n",
      "Params: {'max_iters': 15, 'gamma': 0.03839}, Cross-validated loss: 164.4935915823101\n",
      "Current iteration=0, loss=-1.4079829215994284\n",
      "Current iteration=0, loss=-1.4075367283958387\n",
      "Current iteration=0, loss=-1.4049578498681905\n",
      "Current iteration=0, loss=-1.406425143572237\n",
      "Current iteration=0, loss=-1.411074601539106\n",
      "Params: {'max_iters': 15, 'gamma': 0.03738}, Cross-validated loss: 155.83290096366574\n",
      "Current iteration=0, loss=-1.359577648169615\n",
      "Current iteration=0, loss=-1.3585919874565335\n",
      "Current iteration=0, loss=-1.3582346572595776\n",
      "Current iteration=0, loss=-1.3578372874751026\n",
      "Current iteration=0, loss=-1.3592390231413225\n",
      "Params: {'max_iters': 15, 'gamma': 0.03637}, Cross-validated loss: 147.40853731805515\n",
      "Current iteration=0, loss=-1.308468168563939\n",
      "Current iteration=0, loss=-1.3098286542476638\n",
      "Current iteration=0, loss=-1.3085876067523368\n",
      "Current iteration=0, loss=-1.3087864258328255\n",
      "Current iteration=0, loss=-1.3118057396312994\n",
      "Params: {'max_iters': 15, 'gamma': 0.03536}, Cross-validated loss: 139.22112123509507\n",
      "Current iteration=0, loss=-1.2584495007796586\n",
      "Current iteration=0, loss=-1.2599602063993223\n",
      "Current iteration=0, loss=-1.2623027891821141\n",
      "Current iteration=0, loss=-1.2597637548371963\n",
      "Current iteration=0, loss=-1.2594320592621193\n",
      "Params: {'max_iters': 15, 'gamma': 0.034350000000000006}, Cross-validated loss: 131.2705084150015\n",
      "Current iteration=0, loss=-1.2117273831746087\n",
      "Current iteration=0, loss=-1.2117000064165073\n",
      "Current iteration=0, loss=-1.2116515233584046\n",
      "Current iteration=0, loss=-1.2079052215839274\n",
      "Current iteration=0, loss=-1.2077436098338956\n",
      "Params: {'max_iters': 15, 'gamma': 0.03334000000000001}, Cross-validated loss: 123.5556581664442\n",
      "Current iteration=0, loss=-1.159076911446593\n",
      "Current iteration=0, loss=-1.161521228980159\n",
      "Current iteration=0, loss=-1.1602932812919562\n",
      "Current iteration=0, loss=-1.1588490018590607\n",
      "Current iteration=0, loss=-1.1601303887026198\n",
      "Params: {'max_iters': 15, 'gamma': 0.03233}, Cross-validated loss: 116.07632332622534\n",
      "Current iteration=0, loss=-1.1089022278993073\n",
      "Current iteration=0, loss=-1.1085209954874329\n",
      "Current iteration=0, loss=-1.1118891013654222\n",
      "Current iteration=0, loss=-1.1110513740554777\n",
      "Current iteration=0, loss=-1.1069122344930347\n",
      "Params: {'max_iters': 15, 'gamma': 0.03132}, Cross-validated loss: 108.83348901728796\n",
      "Current iteration=0, loss=-1.0589777842313388\n",
      "Current iteration=0, loss=-1.0605946958423376\n",
      "Current iteration=0, loss=-1.0587163257911014\n",
      "Current iteration=0, loss=-1.058278506116726\n",
      "Current iteration=0, loss=-1.0563209304813135\n",
      "Params: {'max_iters': 15, 'gamma': 0.030310000000000004}, Cross-validated loss: 101.82550429534889\n",
      "Current iteration=0, loss=-1.004295966052034\n",
      "Current iteration=0, loss=-1.0091509843587747\n",
      "Current iteration=0, loss=-1.0083816530947807\n",
      "Current iteration=0, loss=-1.0096682943926876\n",
      "Current iteration=0, loss=-1.0051488401326591\n",
      "Params: {'max_iters': 15, 'gamma': 0.029300000000000007}, Cross-validated loss: 95.05330023375238\n",
      "Current iteration=0, loss=-0.9571630106441031\n",
      "Current iteration=0, loss=-0.9545461071460224\n",
      "Current iteration=0, loss=-0.9550094267937084\n",
      "Current iteration=0, loss=-0.955749765574624\n",
      "Current iteration=0, loss=-0.9560117181970258\n",
      "Params: {'max_iters': 15, 'gamma': 0.028289999999999996}, Cross-validated loss: 88.51619846049864\n",
      "Current iteration=0, loss=-0.9042644338470969\n",
      "Current iteration=0, loss=-0.9042597098169065\n",
      "Current iteration=0, loss=-0.9029726106238454\n",
      "Current iteration=0, loss=-0.9027186503980831\n",
      "Current iteration=0, loss=-0.9041335198035462\n",
      "Params: {'max_iters': 15, 'gamma': 0.02728}, Cross-validated loss: 82.21321426301986\n",
      "Current iteration=0, loss=-0.8511100750417646\n",
      "Current iteration=0, loss=-0.8511135124145456\n",
      "Current iteration=0, loss=-0.8519478046248106\n",
      "Current iteration=0, loss=-0.8504859186720201\n",
      "Current iteration=0, loss=-0.8515162229021768\n",
      "Params: {'max_iters': 15, 'gamma': 0.02627}, Cross-validated loss: 76.14525090557012\n",
      "Current iteration=0, loss=-0.7979252328828103\n",
      "Current iteration=0, loss=-0.8008758738452957\n",
      "Current iteration=0, loss=-0.7957337786578071\n",
      "Current iteration=0, loss=-0.7990758964063477\n",
      "Current iteration=0, loss=-0.7982936255485957\n",
      "Params: {'max_iters': 15, 'gamma': 0.025260000000000005}, Cross-validated loss: 70.31132887495338\n",
      "Current iteration=0, loss=-0.745261881073067\n",
      "Current iteration=0, loss=-0.7448000709369056\n",
      "Current iteration=0, loss=-0.7467226800926254\n",
      "Current iteration=0, loss=-0.7453462682688057\n",
      "Current iteration=0, loss=-0.7433300432648425\n",
      "Params: {'max_iters': 15, 'gamma': 0.024250000000000008}, Cross-validated loss: 64.71199613553404\n",
      "Current iteration=0, loss=-0.6903623589993889\n",
      "Current iteration=0, loss=-0.6911732266567027\n",
      "Current iteration=0, loss=-0.6919681501375208\n",
      "Current iteration=0, loss=-0.6921390093687493\n",
      "Current iteration=0, loss=-0.6911578013183866\n",
      "Params: {'max_iters': 15, 'gamma': 0.023239999999999997}, Cross-validated loss: 59.346235078933695\n",
      "Current iteration=0, loss=-0.6375827280324902\n",
      "Current iteration=0, loss=-0.636412241425219\n",
      "Current iteration=0, loss=-0.6378994494914779\n",
      "Current iteration=0, loss=-0.6375654830409185\n",
      "Current iteration=0, loss=-0.6363951207305805\n",
      "Params: {'max_iters': 15, 'gamma': 0.02223}, Cross-validated loss: 54.21418003811452\n",
      "Current iteration=0, loss=-0.5830456445326734\n",
      "Current iteration=0, loss=-0.5822188448325339\n",
      "Current iteration=0, loss=-0.5829159599534363\n",
      "Current iteration=0, loss=-0.582141755239618\n",
      "Current iteration=0, loss=-0.5822305916160274\n",
      "Params: {'max_iters': 15, 'gamma': 0.021220000000000003}, Cross-validated loss: 49.316182836068904\n",
      "Current iteration=0, loss=-0.5270043969257476\n",
      "Current iteration=0, loss=-0.529306230681319\n",
      "Current iteration=0, loss=-0.5268963357707318\n",
      "Current iteration=0, loss=-0.5268878045012048\n",
      "Current iteration=0, loss=-0.5267525902881464\n",
      "Params: {'max_iters': 15, 'gamma': 0.020210000000000006}, Cross-validated loss: 44.65123504261256\n",
      "Current iteration=0, loss=-0.47070377475764946\n",
      "Current iteration=0, loss=-0.47238011646541284\n",
      "Current iteration=0, loss=-0.4714988533913419\n",
      "Current iteration=0, loss=-0.47199360962522646\n",
      "Current iteration=0, loss=-0.472094575397446\n",
      "Params: {'max_iters': 15, 'gamma': 0.019199999999999995}, Cross-validated loss: 40.21943687244632\n",
      "Current iteration=0, loss=-0.41593803966504156\n",
      "Current iteration=0, loss=-0.416263995872485\n",
      "Current iteration=0, loss=-0.41467046404687274\n",
      "Current iteration=0, loss=-0.4158339224045405\n",
      "Current iteration=0, loss=-0.4152604570039034\n",
      "Params: {'max_iters': 15, 'gamma': 0.018189999999999998}, Cross-validated loss: 36.02060737809223\n",
      "Current iteration=0, loss=-0.35874640883319364\n",
      "Current iteration=0, loss=-0.3600876971962598\n",
      "Current iteration=0, loss=-0.3587482103214347\n",
      "Current iteration=0, loss=-0.35927796848546245\n",
      "Current iteration=0, loss=-0.3578185278530445\n",
      "Params: {'max_iters': 15, 'gamma': 0.01718}, Cross-validated loss: 32.05448766413103\n",
      "Current iteration=0, loss=-0.301561347699267\n",
      "Current iteration=0, loss=-0.30239945227667253\n",
      "Current iteration=0, loss=-0.3004860209033524\n",
      "Current iteration=0, loss=-0.3020425679064814\n",
      "Current iteration=0, loss=-0.3022570304954566\n",
      "Params: {'max_iters': 15, 'gamma': 0.016170000000000004}, Cross-validated loss: 28.320881797426154\n",
      "Current iteration=0, loss=-0.24452403986100896\n",
      "Current iteration=0, loss=-0.24449423597535774\n",
      "Current iteration=0, loss=-0.24389117766529703\n",
      "Current iteration=0, loss=-0.24369665654029285\n",
      "Current iteration=0, loss=-0.2435114102673327\n",
      "Params: {'max_iters': 15, 'gamma': 0.015160000000000007}, Cross-validated loss: 24.819434028821092\n",
      "Current iteration=0, loss=-0.18555087598377284\n",
      "Current iteration=0, loss=-0.18586663412621532\n",
      "Current iteration=0, loss=-0.18630880641036715\n",
      "Current iteration=0, loss=-0.18564758417266708\n",
      "Current iteration=0, loss=-0.18536783652295719\n",
      "Params: {'max_iters': 15, 'gamma': 0.014149999999999996}, Cross-validated loss: 21.549702333665003\n",
      "Current iteration=0, loss=-0.1262275371530771\n",
      "Current iteration=0, loss=-0.12649729634818552\n",
      "Current iteration=0, loss=-0.12824286032736767\n",
      "Current iteration=0, loss=-0.1275547325207521\n",
      "Current iteration=0, loss=-0.12604341376561032\n",
      "Params: {'max_iters': 15, 'gamma': 0.013139999999999999}, Cross-validated loss: 18.51140653075687\n",
      "Current iteration=0, loss=-0.06794563789811076\n",
      "Current iteration=0, loss=-0.06656679530782252\n",
      "Current iteration=0, loss=-0.06731320595002226\n",
      "Current iteration=0, loss=-0.06813212093550906\n",
      "Current iteration=0, loss=-0.0675804269648827\n",
      "Params: {'max_iters': 15, 'gamma': 0.012130000000000002}, Cross-validated loss: 15.70408727827108\n",
      "Current iteration=0, loss=-0.007621465723625655\n",
      "Current iteration=0, loss=-0.007830708604437233\n",
      "Current iteration=0, loss=-0.007712773806571416\n",
      "Current iteration=0, loss=-0.006488612056080879\n",
      "Current iteration=0, loss=-0.007965979519338223\n",
      "Params: {'max_iters': 15, 'gamma': 0.011120000000000005}, Cross-validated loss: 13.126908465497161\n",
      "Current iteration=0, loss=0.05345186475282107\n",
      "Current iteration=0, loss=0.05278966769341805\n",
      "Current iteration=0, loss=0.05250491446520428\n",
      "Current iteration=0, loss=0.053687017537895204\n",
      "Current iteration=0, loss=0.05280235045272063\n",
      "Params: {'max_iters': 15, 'gamma': 0.010110000000000008}, Cross-validated loss: 10.77924963272401\n",
      "Current iteration=0, loss=0.11469445460315325\n",
      "Current iteration=0, loss=0.11392243772113801\n",
      "Current iteration=0, loss=0.11367184761187013\n",
      "Current iteration=0, loss=0.11485246845871017\n",
      "Current iteration=0, loss=0.11392774863113321\n",
      "Params: {'max_iters': 15, 'gamma': 0.009099999999999997}, Cross-validated loss: 8.660174077556135\n",
      "Current iteration=0, loss=0.17625393979827894\n",
      "Current iteration=0, loss=0.1751638771073292\n",
      "Current iteration=0, loss=0.17640894483217026\n",
      "Current iteration=0, loss=0.17636058046221148\n",
      "Current iteration=0, loss=0.1757249549774969\n",
      "Params: {'max_iters': 15, 'gamma': 0.00809}, Cross-validated loss: 6.768582432285177\n",
      "Current iteration=0, loss=0.23777610632883175\n",
      "Current iteration=0, loss=0.2390698574405004\n",
      "Current iteration=0, loss=0.23832989051262285\n",
      "Current iteration=0, loss=0.2384696708697656\n",
      "Current iteration=0, loss=0.23816169509034113\n",
      "Params: {'max_iters': 15, 'gamma': 0.007080000000000003}, Cross-validated loss: 5.103902437789069\n",
      "Current iteration=0, loss=0.3010099484165692\n",
      "Current iteration=0, loss=0.3015175925214617\n",
      "Current iteration=0, loss=0.3011374489851626\n",
      "Current iteration=0, loss=0.30178300632457616\n",
      "Current iteration=0, loss=0.3013292811513358\n",
      "Params: {'max_iters': 15, 'gamma': 0.006070000000000006}, Cross-validated loss: 3.665604132625507\n",
      "Current iteration=0, loss=0.3651610649547427\n",
      "Current iteration=0, loss=0.3649501778709074\n",
      "Current iteration=0, loss=0.3650006130885486\n",
      "Current iteration=0, loss=0.36464543374266023\n",
      "Current iteration=0, loss=0.3650929841987282\n",
      "Params: {'max_iters': 15, 'gamma': 0.005059999999999995}, Cross-validated loss: 2.454955263055387\n",
      "Current iteration=0, loss=0.4289033460697064\n",
      "Current iteration=0, loss=0.429281099629104\n",
      "Current iteration=0, loss=0.4291982745499117\n",
      "Current iteration=0, loss=0.4293442049147901\n",
      "Current iteration=0, loss=0.4293225255167481\n",
      "Params: {'max_iters': 15, 'gamma': 0.004049999999999998}, Cross-validated loss: 1.4766710222348762\n",
      "Current iteration=0, loss=0.4941345567935078\n",
      "Current iteration=0, loss=0.4940148200322782\n",
      "Current iteration=0, loss=0.49406608650462375\n",
      "Current iteration=0, loss=0.4942295933830511\n",
      "Current iteration=0, loss=0.493948111264254\n",
      "Params: {'max_iters': 15, 'gamma': 0.003040000000000001}, Cross-validated loss: 0.7432041809248074\n",
      "Current iteration=0, loss=0.5596057556007307\n",
      "Current iteration=0, loss=0.5594548351714419\n",
      "Current iteration=0, loss=0.5596067925350191\n",
      "Current iteration=0, loss=0.5595049964458952\n",
      "Current iteration=0, loss=0.55972314074026\n",
      "Params: {'max_iters': 15, 'gamma': 0.002030000000000004}, Cross-validated loss: 0.28344825446137295\n",
      "Current iteration=0, loss=0.6257326427726774\n",
      "Current iteration=0, loss=0.6256952623888293\n",
      "Current iteration=0, loss=0.6256814470572367\n",
      "Current iteration=0, loss=0.6257311452006782\n",
      "Current iteration=0, loss=0.6257265261390966\n",
      "Params: {'max_iters': 15, 'gamma': 0.001020000000000007}, Cross-validated loss: 0.15962337656370257\n",
      "Current iteration=0, loss=0.6924828684373773\n",
      "Current iteration=0, loss=0.6924827011174925\n",
      "Current iteration=0, loss=0.6924827949259239\n",
      "Current iteration=0, loss=0.6924825526206313\n",
      "Current iteration=0, loss=0.692483676656768\n",
      "Params: {'max_iters': 15, 'gamma': 1e-05}, Cross-validated loss: 0.49379189474334295\n",
      "Best for logistic_regression: Params = {'max_iters': 15, 'gamma': 0.001020000000000007}, Score = 0.15962337656370257\n",
      "\n",
      "logistic_regression: Best params: {'max_iters': 15, 'gamma': 0.001020000000000007}, Best score: 0.15962337656370257\n"
     ]
    }
   ],
   "source": [
    "# Run hyperparameter tuning\n",
    "# Define models and parameter grid (as done before)\n",
    "# Example usage of the tune_hyperparameters function\n",
    "x_train = encoded_x_train\n",
    "initial_weights = np.zeros(x_train.shape[1])  # Initial weights\n",
    "\n",
    "# TODO create loss for regression (-log)\n",
    "\n",
    "tuning_results = tune_hyperparameters(models, param_grid, x_train, y_train, initial_weights, k=5)\n",
    "#tuning_results = tune_hyperparameters1(models, param_grid, x_train, y_train, initial_weights, k=5)\n",
    "#tuning_results = tune_hyperparameters2(models, param_grid, x_train, y_train, k=5)\n",
    "\n",
    "# Print best results for each model\n",
    "for model_name, result in tuning_results.items():\n",
    "    print(f\"{model_name}: Best params: {result['best_params']}, Best score: {result['best_score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) define the parameters\n",
    "initial_w = np.zeros(x_train.shape[1])  # Initial weights\n",
    "max_iters = 100                       # Number of iterations\n",
    "gamma = 0.1                             # Learning rate\n",
    "lambda_ = 0.1                           # Regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) mean_squared_error_gd\n",
    "cv_loss_gd = cross_validate(model_fn=mean_squared_error_gd, X=x_train, y=y_train, k=5, initial_w=initial_w, max_iters=max_iters, gamma=gamma)\n",
    "print(\"Cross-validated loss for mean_squared_error_gd:\", cv_loss_gd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code que j'avais fais avant qd c'tait dans le run, \n",
    "# mtn mthode differente, car run de crossvalidation dans le notebook crossvalidation\n",
    "\n",
    "\n",
    "# ***************** Cross validation ***************** #\n",
    "\n",
    "# Flexible crossvalidation on which function from implementations you want to validate\n",
    "# there are dynamical arguments and you can change the function you want to validate by changing the function name\n",
    "\n",
    "# 0) define the parameters\n",
    "initial_w = np.zeros(x_train.shape[1])  # Initial weights\n",
    "max_iters = 100                       # Number of iterations\n",
    "gamma = 0.1                             # Learning rate\n",
    "lambda_ = 0.1                           # Regularization parameter\n",
    "\n",
    "# 1) mean_squared_error_gd\n",
    "cv_loss_gd = cross_validate(model_fn=mean_squared_error_gd, X=x_train, y=y_train, k=5, initial_w=initial_w, max_iters=max_iters, gamma=gamma)\n",
    "print(\"Cross-validated loss for mean_squared_error_gd:\", cv_loss_gd)\n",
    "\n",
    "# 2) mean_squared_error_sgd\n",
    "cv_loss_sgd = cross_validate(model_fn=mean_squared_error_sgd, X=x_train, y=y_train, k=5, initial_w=initial_w, max_iters=max_iters, gamma=gamma)\n",
    "print(\"Cross-validated loss for mean_squared_error_sgd:\", cv_loss_gd)\n",
    "\n",
    "# 3) least_squares\n",
    "cv_loss_ls = cross_validate(model_fn=least_squares, X=x_train, Y=y_train, k=5)\n",
    "print(\"Cross-validated loss for least_squares:\", cv_loss_ls)\n",
    "\n",
    "# 4) ridge_regression\n",
    "#lambda_ = 0.1\n",
    "#cv_loss_rr = cross_validate(ridge_regression, X=x_train, Y=y_train, k=5, lambda_=lambda_)\n",
    "#print(\"Cross-validated loss for ridge_regression:\", cv_loss_rr)\n",
    "\n",
    "# 5) logistic_regression\n",
    "cv_loss_lr = cross_validate(\n",
    "    model_fn=logistic_regression,  # Pass the logistic regression function\n",
    "    X=x_train,\n",
    "    y=y_train,\n",
    "    k=5,\n",
    "    initial_w=initial_w,\n",
    "    max_iters=max_iters,\n",
    "    gamma=gamma\n",
    "    )\n",
    "print(\"Cross-validated loss for logistic_regression:\", cv_loss_lr)\n",
    "\n",
    "# 6) reg_logistic_regression\n",
    "cv_loss_rlr = cross_validate(\n",
    "    model_fn=reg_logistic_regression,  # Pass the regularized logistic regression function\n",
    "    X=x_train,\n",
    "    y=y_train,\n",
    "    k=5, initial_w=initial_w, max_iters=max_iters, gamma=gamma,lambda_=lambda_\n",
    ")\n",
    "print(\"Cross-validated loss for reg_logistic_regression:\", cv_loss_rlr)\n",
    "\n",
    "# 4) Ridge Regression : cross validate + fine tuning of parameters\n",
    "# Define ranges for hyperparameters\n",
    "gamma_values = [0.01, 0.1, 0.5]\n",
    "lambda_values = [0.01, 0.1, 1, 10]\n",
    "\n",
    "best_score = float('inf')\n",
    "best_params = {}\n",
    "\n",
    "# Perform grid search over gamma and lambda_\n",
    "for gamma in gamma_values:\n",
    "    for lambda_ in lambda_values:\n",
    "        cv_loss_rr = cross_validate(model_fn=ridge_regression,X=x_train,y=y_train,k=5,gamma=gamma,lambda_=lambda_)\n",
    "        print(f\"Cross-validated loss with gamma={gamma}, lambda_={lambda_}: {cv_loss_rr}\")\n",
    "        \n",
    "        # Update best score and parameters\n",
    "        if cv_loss_rr < best_score:\n",
    "            best_score = cv_loss_rr\n",
    "            best_params = {'gamma': gamma, 'lambda_': lambda_}\n",
    "\n",
    "print(f\"The best parameters: {best_params} yield a cross-validated loss of: {best_score}\")\n",
    "\n",
    "\n",
    "# LOOCV: To perform Leave-One-Out Cross-Validation --> just call cross_validate with k=len(y)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
